{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YbTQas2ZTT8k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import multiprocess as mp\n",
    "from libs.TicTacToe import TicTacToe\n",
    "from libs.model import create_az_model\n",
    "from libs.MCTS import MCTS\n",
    "from libs.Trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Number of cores]: 16\n"
     ]
    }
   ],
   "source": [
    "n_cores = mp.cpu_count()\n",
    "print(f\"[Number of cores]: {n_cores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tic-Tac-Toe engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.array([0., 0., -1., -1., 1., -1., 1., 1., 0.])\n",
    "TicTacToe().get_available_actions(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptC0Q77hf3l5",
    "outputId": "31290fd4-5179-4524-a2e2-8a9795ec8dea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]] \n",
      "\n",
      "[[ 0.  0.  0.]\n",
      " [-1.  0.  0.]\n",
      " [ 0.  0.  1.]] \n",
      "\n",
      "[[ 0.  0.  0.]\n",
      " [-1.  0.  1.]\n",
      " [ 0.  0.  1.]] \n",
      "\n",
      "[[ 0.  0.  0.]\n",
      " [-1.  0.  1.]\n",
      " [ 0. -1.  1.]] \n",
      "\n",
      "[[ 1.  0.  0.]\n",
      " [-1.  0.  1.]\n",
      " [ 0. -1.  1.]] \n",
      "\n",
      "[[ 1.  0. -1.]\n",
      " [-1.  0.  1.]\n",
      " [ 0. -1.  1.]] \n",
      "\n",
      "[[ 1.  0. -1.]\n",
      " [-1.  0.  1.]\n",
      " [ 1. -1.  1.]] \n",
      "\n",
      "[[ 1.  0. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1. -1.  1.]] \n",
      "\n",
      "[[ 1.  1. -1.]\n",
      " [-1. -1.  1.]\n",
      " [ 1. -1.  1.]] \n",
      "\n",
      "[Winner]: 0\n"
     ]
    }
   ],
   "source": [
    "ttt = TicTacToe()\n",
    "\n",
    "while ttt.status==\"Ongoing\":\n",
    "\n",
    "    valid_moves = ttt.next_moves()\n",
    "    new_board = random.choice(valid_moves)\n",
    "    ttt.play(new_board)\n",
    "    print(np.reshape(ttt.board, (3,3)),\"\\n\")\n",
    "    if len(valid_moves)==0:\n",
    "        break\n",
    "\n",
    "print(\"[Winner]:\",ttt.winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create policy and probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3sWR-mnAT5YL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_az_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jdHZgJCUGx5",
    "outputId": "4bd3f03d-2edf-49bb-a30e-45c61e32264d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tictactoe_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]                  0         []                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 9)                    0         ['input_1[0][0]']             \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)        (None, 9)                    0         ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " tf.one_hot (TFOpLambda)     (None, 9, 3)                 0         ['tf.cast[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)      (None, 9, 3)                 0         ['tf.one_hot[0][0]']          \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)     (None, 3, 3, 3)              0         ['tf.cast_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 1, 1, 243)            6804      ['tf.reshape[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 1, 1, 243)            972       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 1, 1, 243)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 1, 1, 243)            59292     ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 1, 1, 243)            972       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 27)                   0         ['tf.cast_1[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 243)                  0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 270)                  0         ['flatten_1[0][0]',           \n",
      "                                                                     'flatten[0][0]']             \n",
      "                                                                                                  \n",
      " residual_tower (ReLU)       (None, 270)                  0         ['tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 270, 1)               0         ['residual_tower[0][0]']      \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 270, 1)               0         ['residual_tower[0][0]']      \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 270, 1)               2         ['tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 270, 2)               4         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 270, 1)               4         ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 270, 2)               8         ['conv1d[0][0]']              \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 270, 1)               0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 270, 2)               0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 270)                  0         ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 540)                  0         ['re_lu_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  69376     ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " policy (Dense)              (None, 9)                    4869      ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " value (Dense)               (None, 1)                    257       ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 142560 (556.88 KB)\n",
      "Trainable params: 141582 (553.05 KB)\n",
      "Non-trainable params: 978 (3.82 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "B34kQiM_HJsc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts = MCTS(game=TicTacToe(), n_simulations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array([0., 0., -1., -1., 1., -1., 1., 1., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "root = mcts.run(model=model, state=state, player=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State:\n",
       "[ 0.  0. -1. -1.  1. -1.  1.  1.  0.]\n",
       "Player:1\n",
       "Value:0.96\n",
       "Leaf:False\n",
       "Visits:100\n",
       "Children:\n",
       " -0: prior=0.3333333333333333\n",
       " -1: prior=0.3333333333333333\n",
       " -8: prior=0.3333333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_TEMPERATURE = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 15.1300208568573 seconds\n"
     ]
    }
   ],
   "source": [
    "# speed test on 100 games\n",
    "start_time = time.time()\n",
    "trainer = Trainer(game = TicTacToe, mcts = MCTS, model=None)\n",
    "dataset = trainer.create_dataset(number_of_games=100, temperature=starting_temperature)\n",
    "print(\"Running time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_fn(n):\n",
    "    from libs.Trainer import Trainer\n",
    "    from libs.TicTacToe import TicTacToe\n",
    "    from libs.MCTS import MCTS\n",
    "    N_GAMES_PER_JOB = 25\n",
    "    starting_temperature = 10.0\n",
    "    trainer = Trainer(game = TicTacToe, mcts = MCTS, model=None)\n",
    "    game_batch = trainer.create_dataset(number_of_games=N_GAMES_PER_JOB, temperature=STARTING_TEMPERATURE)\n",
    "    return game_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 17.62233281135559 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ctx = mp.get_context(\"spawn\")\n",
    "pool = ctx.Pool(n_cores)\n",
    "dataset = pool.map(parallel_fn, range(n_cores))\n",
    "print(\"Running time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GAMES_PER_JOB = 25\n",
    "filename = str(N_GAMES_PER_JOB*n_cores)+\"_tictactoe_temperature_\"+str(starting_temperature)+\".pickle\"\n",
    "\n",
    "flatten_dataset = []\n",
    "for batch in dataset:\n",
    "    flatten_dataset += batch\n",
    "    \n",
    "with open(filename, \"wb\") as fp:\n",
    "    pickle.dump(flatten_dataset, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(game = TicTacToe, mcts = MCTS, model=create_az_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(filename, 'rb') as handle:\n",
    "    dataset = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 3.5886 - policy_loss: 1.8836 - value_loss: 1.6082 - val_loss: 3.0477 - val_policy_loss: 2.1091 - val_value_loss: 0.8242 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.6339 - policy_loss: 1.6385 - value_loss: 0.8821 - val_loss: 3.0722 - val_policy_loss: 2.1497 - val_value_loss: 0.8138 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.4557 - policy_loss: 1.5156 - value_loss: 0.8340 - val_loss: 2.5625 - val_policy_loss: 1.6481 - val_value_loss: 0.8123 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.4074 - policy_loss: 1.4710 - value_loss: 0.8350 - val_loss: 2.4468 - val_policy_loss: 1.5361 - val_value_loss: 0.8123 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3708 - policy_loss: 1.4393 - value_loss: 0.8336 - val_loss: 2.3364 - val_policy_loss: 1.4290 - val_value_loss: 0.8124 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3390 - policy_loss: 1.4111 - value_loss: 0.8338 - val_loss: 2.2954 - val_policy_loss: 1.3912 - val_value_loss: 0.8125 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3170 - policy_loss: 1.3922 - value_loss: 0.8331 - val_loss: 2.2707 - val_policy_loss: 1.3682 - val_value_loss: 0.8128 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3134 - policy_loss: 1.3898 - value_loss: 0.8331 - val_loss: 2.2700 - val_policy_loss: 1.3683 - val_value_loss: 0.8124 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3025 - policy_loss: 1.3792 - value_loss: 0.8330 - val_loss: 2.2646 - val_policy_loss: 1.3636 - val_value_loss: 0.8125 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3075 - policy_loss: 1.3822 - value_loss: 0.8329 - val_loss: 2.2740 - val_policy_loss: 1.3688 - val_value_loss: 0.8136 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2968 - policy_loss: 1.3709 - value_loss: 0.8330 - val_loss: 2.3331 - val_policy_loss: 1.4294 - val_value_loss: 0.8123 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3040 - policy_loss: 1.3781 - value_loss: 0.8336 - val_loss: 2.3626 - val_policy_loss: 1.4587 - val_value_loss: 0.8129 - lr: 0.0099\n",
      "Epoch 13/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.3253 - policy_loss: 1.3921 - value_loss: 0.8333 - val_loss: 2.2864 - val_policy_loss: 1.3739 - val_value_loss: 0.8123 - lr: 0.0097\n",
      "Epoch 14/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3271 - policy_loss: 1.3874 - value_loss: 0.8339 - val_loss: 2.3713 - val_policy_loss: 1.4536 - val_value_loss: 0.8123 - lr: 0.0094\n",
      "Epoch 15/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.3022 - policy_loss: 1.3652 - value_loss: 0.8329 - val_loss: 2.2719 - val_policy_loss: 1.3574 - val_value_loss: 0.8132 - lr: 0.0090\n",
      "Epoch 16/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2889 - policy_loss: 1.3565 - value_loss: 0.8331 - val_loss: 2.2460 - val_policy_loss: 1.3370 - val_value_loss: 0.8123 - lr: 0.0086\n",
      "Epoch 17/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2711 - policy_loss: 1.3422 - value_loss: 0.8331 - val_loss: 2.2570 - val_policy_loss: 1.3516 - val_value_loss: 0.8125 - lr: 0.0081\n",
      "Epoch 18/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2660 - policy_loss: 1.3392 - value_loss: 0.8341 - val_loss: 2.2499 - val_policy_loss: 1.3465 - val_value_loss: 0.8128 - lr: 0.0076\n",
      "Epoch 19/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2660 - policy_loss: 1.3418 - value_loss: 0.8331 - val_loss: 2.2582 - val_policy_loss: 1.3567 - val_value_loss: 0.8124 - lr: 0.0070\n",
      "Epoch 20/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2570 - policy_loss: 1.3351 - value_loss: 0.8329 - val_loss: 2.2477 - val_policy_loss: 1.3480 - val_value_loss: 0.8124 - lr: 0.0064\n",
      "Epoch 21/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2458 - policy_loss: 1.3278 - value_loss: 0.8325 - val_loss: 2.2162 - val_policy_loss: 1.3192 - val_value_loss: 0.8134 - lr: 0.0058\n",
      "Epoch 22/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2746 - policy_loss: 1.3529 - value_loss: 0.8336 - val_loss: 2.2360 - val_policy_loss: 1.3357 - val_value_loss: 0.8123 - lr: 0.0052\n",
      "Epoch 23/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2531 - policy_loss: 1.3322 - value_loss: 0.8329 - val_loss: 2.2215 - val_policy_loss: 1.3226 - val_value_loss: 0.8123 - lr: 0.0046\n",
      "Epoch 24/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2491 - policy_loss: 1.3281 - value_loss: 0.8328 - val_loss: 2.2172 - val_policy_loss: 1.3179 - val_value_loss: 0.8123 - lr: 0.0040\n",
      "Epoch 25/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2356 - policy_loss: 1.3163 - value_loss: 0.8326 - val_loss: 2.2112 - val_policy_loss: 1.3137 - val_value_loss: 0.8123 - lr: 0.0035\n",
      "Epoch 26/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2239 - policy_loss: 1.3069 - value_loss: 0.8327 - val_loss: 2.1990 - val_policy_loss: 1.3038 - val_value_loss: 0.8123 - lr: 0.0030\n",
      "Epoch 27/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.2228 - policy_loss: 1.3079 - value_loss: 0.8327 - val_loss: 2.1898 - val_policy_loss: 1.2966 - val_value_loss: 0.8123 - lr: 0.0026\n",
      "Epoch 28/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2090 - policy_loss: 1.2958 - value_loss: 0.8327 - val_loss: 2.1918 - val_policy_loss: 1.3000 - val_value_loss: 0.8123 - lr: 0.0022\n",
      "Epoch 29/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.2052 - policy_loss: 1.2934 - value_loss: 0.8328 - val_loss: 2.1829 - val_policy_loss: 1.2925 - val_value_loss: 0.8123 - lr: 0.0018\n",
      "Epoch 30/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1978 - policy_loss: 1.2880 - value_loss: 0.8325 - val_loss: 2.1790 - val_policy_loss: 1.2903 - val_value_loss: 0.8123 - lr: 0.0015\n",
      "Epoch 31/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1950 - policy_loss: 1.2865 - value_loss: 0.8325 - val_loss: 2.1788 - val_policy_loss: 1.2913 - val_value_loss: 0.8123 - lr: 0.0012\n",
      "Epoch 32/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1884 - policy_loss: 1.2812 - value_loss: 0.8324 - val_loss: 2.1753 - val_policy_loss: 1.2888 - val_value_loss: 0.8124 - lr: 9.9261e-04\n",
      "Epoch 33/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1897 - policy_loss: 1.2834 - value_loss: 0.8325 - val_loss: 2.1746 - val_policy_loss: 1.2889 - val_value_loss: 0.8123 - lr: 7.9659e-04\n",
      "Epoch 34/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1868 - policy_loss: 1.2813 - value_loss: 0.8324 - val_loss: 2.1718 - val_policy_loss: 1.2869 - val_value_loss: 0.8123 - lr: 6.3292e-04\n",
      "Epoch 35/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1831 - policy_loss: 1.2783 - value_loss: 0.8325 - val_loss: 2.1688 - val_policy_loss: 1.2845 - val_value_loss: 0.8123 - lr: 4.9787e-04\n",
      "Epoch 36/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1805 - policy_loss: 1.2763 - value_loss: 0.8324 - val_loss: 2.1688 - val_policy_loss: 1.2850 - val_value_loss: 0.8123 - lr: 3.8774e-04\n",
      "Epoch 37/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1772 - policy_loss: 1.2734 - value_loss: 0.8324 - val_loss: 2.1696 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 2.9897e-04\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1754 - policy_loss: 1.2720 - value_loss: 0.8324 - val_loss: 2.1686 - val_policy_loss: 1.2854 - val_value_loss: 0.8123 - lr: 2.2823e-04\n",
      "Epoch 39/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1776 - policy_loss: 1.2744 - value_loss: 0.8324 - val_loss: 2.1678 - val_policy_loss: 1.2848 - val_value_loss: 0.8123 - lr: 1.7249e-04\n",
      "Epoch 40/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1761 - policy_loss: 1.2732 - value_loss: 0.8324 - val_loss: 2.1679 - val_policy_loss: 1.2851 - val_value_loss: 0.8123 - lr: 1.2907e-04\n",
      "Epoch 41/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1758 - policy_loss: 1.2730 - value_loss: 0.8324 - val_loss: 2.1681 - val_policy_loss: 1.2854 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1735 - policy_loss: 1.2708 - value_loss: 0.8324 - val_loss: 2.1679 - val_policy_loss: 1.2854 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1749 - policy_loss: 1.2724 - value_loss: 0.8324 - val_loss: 2.1688 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1734 - policy_loss: 1.2710 - value_loss: 0.8324 - val_loss: 2.1675 - val_policy_loss: 1.2853 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1727 - policy_loss: 1.2704 - value_loss: 0.8324 - val_loss: 2.1680 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1737 - policy_loss: 1.2716 - value_loss: 0.8324 - val_loss: 2.1680 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1735 - policy_loss: 1.2715 - value_loss: 0.8324 - val_loss: 2.1687 - val_policy_loss: 1.2870 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1732 - policy_loss: 1.2715 - value_loss: 0.8324 - val_loss: 2.1678 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1712 - policy_loss: 1.2695 - value_loss: 0.8324 - val_loss: 2.1684 - val_policy_loss: 1.2869 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1702 - policy_loss: 1.2688 - value_loss: 0.8324 - val_loss: 2.1680 - val_policy_loss: 1.2867 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1722 - policy_loss: 1.2709 - value_loss: 0.8324 - val_loss: 2.1676 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1719 - policy_loss: 1.2707 - value_loss: 0.8324 - val_loss: 2.1676 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1702 - policy_loss: 1.2692 - value_loss: 0.8324 - val_loss: 2.1668 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1709 - policy_loss: 1.2700 - value_loss: 0.8324 - val_loss: 2.1669 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1695 - policy_loss: 1.2688 - value_loss: 0.8324 - val_loss: 2.1673 - val_policy_loss: 1.2868 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1688 - policy_loss: 1.2682 - value_loss: 0.8324 - val_loss: 2.1666 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1691 - policy_loss: 1.2686 - value_loss: 0.8324 - val_loss: 2.1658 - val_policy_loss: 1.2856 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1687 - policy_loss: 1.2685 - value_loss: 0.8324 - val_loss: 2.1658 - val_policy_loss: 1.2857 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1706 - policy_loss: 1.2705 - value_loss: 0.8324 - val_loss: 2.1662 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1668 - policy_loss: 1.2669 - value_loss: 0.8324 - val_loss: 2.1660 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1699 - policy_loss: 1.2702 - value_loss: 0.8324 - val_loss: 2.1657 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1668 - policy_loss: 1.2672 - value_loss: 0.8324 - val_loss: 2.1663 - val_policy_loss: 1.2869 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1679 - policy_loss: 1.2684 - value_loss: 0.8324 - val_loss: 2.1660 - val_policy_loss: 1.2868 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1667 - policy_loss: 1.2674 - value_loss: 0.8324 - val_loss: 2.1655 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1668 - policy_loss: 1.2677 - value_loss: 0.8324 - val_loss: 2.1649 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1679 - policy_loss: 1.2690 - value_loss: 0.8324 - val_loss: 2.1647 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1703 - policy_loss: 1.2715 - value_loss: 0.8324 - val_loss: 2.1649 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1680 - policy_loss: 1.2694 - value_loss: 0.8324 - val_loss: 2.1650 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1671 - policy_loss: 1.2686 - value_loss: 0.8324 - val_loss: 2.1644 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1662 - policy_loss: 1.2680 - value_loss: 0.8324 - val_loss: 2.1648 - val_policy_loss: 1.2867 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1660 - policy_loss: 1.2679 - value_loss: 0.8324 - val_loss: 2.1643 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1661 - policy_loss: 1.2682 - value_loss: 0.8324 - val_loss: 2.1640 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1652 - policy_loss: 1.2675 - value_loss: 0.8324 - val_loss: 2.1641 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1642 - policy_loss: 1.2666 - value_loss: 0.8324 - val_loss: 2.1641 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1641 - policy_loss: 1.2667 - value_loss: 0.8324 - val_loss: 2.1638 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1647 - policy_loss: 1.2674 - value_loss: 0.8324 - val_loss: 2.1633 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1643 - policy_loss: 1.2672 - value_loss: 0.8324 - val_loss: 2.1634 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1641 - policy_loss: 1.2672 - value_loss: 0.8324 - val_loss: 2.1632 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1654 - policy_loss: 1.2686 - value_loss: 0.8324 - val_loss: 2.1631 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1619 - policy_loss: 1.2652 - value_loss: 0.8324 - val_loss: 2.1630 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1611 - policy_loss: 1.2646 - value_loss: 0.8324 - val_loss: 2.1622 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1628 - policy_loss: 1.2664 - value_loss: 0.8324 - val_loss: 2.1616 - val_policy_loss: 1.2855 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1627 - policy_loss: 1.2665 - value_loss: 0.8324 - val_loss: 2.1610 - val_policy_loss: 1.2850 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1614 - policy_loss: 1.2654 - value_loss: 0.8324 - val_loss: 2.1617 - val_policy_loss: 1.2858 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1630 - policy_loss: 1.2672 - value_loss: 0.8324 - val_loss: 2.1622 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1631 - policy_loss: 1.2674 - value_loss: 0.8324 - val_loss: 2.1615 - val_policy_loss: 1.2860 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1603 - policy_loss: 1.2648 - value_loss: 0.8324 - val_loss: 2.1614 - val_policy_loss: 1.2860 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1612 - policy_loss: 1.2658 - value_loss: 0.8324 - val_loss: 2.1608 - val_policy_loss: 1.2856 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1624 - policy_loss: 1.2672 - value_loss: 0.8324 - val_loss: 2.1602 - val_policy_loss: 1.2852 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1584 - policy_loss: 1.2633 - value_loss: 0.8324 - val_loss: 2.1599 - val_policy_loss: 1.2851 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1594 - policy_loss: 1.2645 - value_loss: 0.8324 - val_loss: 2.1598 - val_policy_loss: 1.2850 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1600 - policy_loss: 1.2653 - value_loss: 0.8324 - val_loss: 2.1598 - val_policy_loss: 1.2852 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1592 - policy_loss: 1.2646 - value_loss: 0.8324 - val_loss: 2.1606 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1609 - policy_loss: 1.2665 - value_loss: 0.8324 - val_loss: 2.1599 - val_policy_loss: 1.2857 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1593 - policy_loss: 1.2651 - value_loss: 0.8324 - val_loss: 2.1600 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1597 - policy_loss: 1.2656 - value_loss: 0.8324 - val_loss: 2.1599 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1600 - policy_loss: 1.2660 - value_loss: 0.8324 - val_loss: 2.1590 - val_policy_loss: 1.2852 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1627 - policy_loss: 1.2689 - value_loss: 0.8324 - val_loss: 2.1588 - val_policy_loss: 1.2852 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1600 - policy_loss: 1.2664 - value_loss: 0.8324 - val_loss: 2.1596 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1575 - policy_loss: 1.2641 - value_loss: 0.8324 - val_loss: 2.1589 - val_policy_loss: 1.2856 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1574 - policy_loss: 1.2641 - value_loss: 0.8324 - val_loss: 2.1587 - val_policy_loss: 1.2855 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1581 - policy_loss: 1.2649 - value_loss: 0.8324 - val_loss: 2.1591 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1575 - policy_loss: 1.2645 - value_loss: 0.8324 - val_loss: 2.1589 - val_policy_loss: 1.2860 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1570 - policy_loss: 1.2641 - value_loss: 0.8324 - val_loss: 2.1585 - val_policy_loss: 1.2858 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1559 - policy_loss: 1.2631 - value_loss: 0.8324 - val_loss: 2.1584 - val_policy_loss: 1.2858 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1557 - policy_loss: 1.2631 - value_loss: 0.8324 - val_loss: 2.1589 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1568 - policy_loss: 1.2643 - value_loss: 0.8324 - val_loss: 2.1579 - val_policy_loss: 1.2856 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1575 - policy_loss: 1.2652 - value_loss: 0.8324 - val_loss: 2.1581 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1572 - policy_loss: 1.2651 - value_loss: 0.8324 - val_loss: 2.1580 - val_policy_loss: 1.2860 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1564 - policy_loss: 1.2643 - value_loss: 0.8324 - val_loss: 2.1587 - val_policy_loss: 1.2868 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1550 - policy_loss: 1.2631 - value_loss: 0.8324 - val_loss: 2.1577 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1584 - policy_loss: 1.2666 - value_loss: 0.8324 - val_loss: 2.1568 - val_policy_loss: 1.2852 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1554 - policy_loss: 1.2638 - value_loss: 0.8324 - val_loss: 2.1564 - val_policy_loss: 1.2850 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1535 - policy_loss: 1.2620 - value_loss: 0.8324 - val_loss: 2.1574 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1560 - policy_loss: 1.2647 - value_loss: 0.8324 - val_loss: 2.1575 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1533 - policy_loss: 1.2621 - value_loss: 0.8324 - val_loss: 2.1571 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1554 - policy_loss: 1.2643 - value_loss: 0.8324 - val_loss: 2.1572 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1538 - policy_loss: 1.2629 - value_loss: 0.8324 - val_loss: 2.1567 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1541 - policy_loss: 1.2634 - value_loss: 0.8324 - val_loss: 2.1570 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1547 - policy_loss: 1.2641 - value_loss: 0.8324 - val_loss: 2.1570 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1536 - policy_loss: 1.2631 - value_loss: 0.8324 - val_loss: 2.1566 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1541 - policy_loss: 1.2638 - value_loss: 0.8324 - val_loss: 2.1564 - val_policy_loss: 1.2862 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1528 - policy_loss: 1.2626 - value_loss: 0.8324 - val_loss: 2.1563 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1560 - policy_loss: 1.2659 - value_loss: 0.8324 - val_loss: 2.1564 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1541 - policy_loss: 1.2642 - value_loss: 0.8324 - val_loss: 2.1570 - val_policy_loss: 1.2872 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1527 - policy_loss: 1.2630 - value_loss: 0.8324 - val_loss: 2.1559 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1536 - policy_loss: 1.2640 - value_loss: 0.8324 - val_loss: 2.1555 - val_policy_loss: 1.2861 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1554 - policy_loss: 1.2659 - value_loss: 0.8324 - val_loss: 2.1561 - val_policy_loss: 1.2867 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1518 - policy_loss: 1.2625 - value_loss: 0.8324 - val_loss: 2.1557 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1522 - policy_loss: 1.2630 - value_loss: 0.8324 - val_loss: 2.1554 - val_policy_loss: 1.2864 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1525 - policy_loss: 1.2634 - value_loss: 0.8324 - val_loss: 2.1556 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1522 - policy_loss: 1.2633 - value_loss: 0.8324 - val_loss: 2.1551 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1521 - policy_loss: 1.2633 - value_loss: 0.8324 - val_loss: 2.1558 - val_policy_loss: 1.2871 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1506 - policy_loss: 1.2620 - value_loss: 0.8324 - val_loss: 2.1552 - val_policy_loss: 1.2867 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1517 - policy_loss: 1.2632 - value_loss: 0.8324 - val_loss: 2.1550 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1531 - policy_loss: 1.2647 - value_loss: 0.8324 - val_loss: 2.1548 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1527 - policy_loss: 1.2645 - value_loss: 0.8324 - val_loss: 2.1555 - val_policy_loss: 1.2874 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1521 - policy_loss: 1.2640 - value_loss: 0.8324 - val_loss: 2.1549 - val_policy_loss: 1.2869 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1513 - policy_loss: 1.2633 - value_loss: 0.8324 - val_loss: 2.1551 - val_policy_loss: 1.2873 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1493 - policy_loss: 1.2614 - value_loss: 0.8324 - val_loss: 2.1548 - val_policy_loss: 1.2871 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1487 - policy_loss: 1.2610 - value_loss: 0.8324 - val_loss: 2.1550 - val_policy_loss: 1.2874 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1530 - policy_loss: 1.2654 - value_loss: 0.8324 - val_loss: 2.1552 - val_policy_loss: 1.2877 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1501 - policy_loss: 1.2626 - value_loss: 0.8324 - val_loss: 2.1529 - val_policy_loss: 1.2856 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1504 - policy_loss: 1.2630 - value_loss: 0.8324 - val_loss: 2.1529 - val_policy_loss: 1.2857 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1494 - policy_loss: 1.2622 - value_loss: 0.8324 - val_loss: 2.1530 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1500 - policy_loss: 1.2628 - value_loss: 0.8324 - val_loss: 2.1529 - val_policy_loss: 1.2860 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1482 - policy_loss: 1.2613 - value_loss: 0.8324 - val_loss: 2.1526 - val_policy_loss: 1.2858 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1476 - policy_loss: 1.2608 - value_loss: 0.8324 - val_loss: 2.1521 - val_policy_loss: 1.2854 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1484 - policy_loss: 1.2617 - value_loss: 0.8324 - val_loss: 2.1522 - val_policy_loss: 1.2856 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1508 - policy_loss: 1.2642 - value_loss: 0.8324 - val_loss: 2.1519 - val_policy_loss: 1.2855 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1488 - policy_loss: 1.2623 - value_loss: 0.8324 - val_loss: 2.1517 - val_policy_loss: 1.2853 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1484 - policy_loss: 1.2620 - value_loss: 0.8324 - val_loss: 2.1521 - val_policy_loss: 1.2859 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1475 - policy_loss: 1.2613 - value_loss: 0.8324 - val_loss: 2.1527 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 154/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1461 - policy_loss: 1.2600 - value_loss: 0.8324 - val_loss: 2.1528 - val_policy_loss: 1.2868 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1470 - policy_loss: 1.2609 - value_loss: 0.8324 - val_loss: 2.1524 - val_policy_loss: 1.2865 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1466 - policy_loss: 1.2607 - value_loss: 0.8324 - val_loss: 2.1521 - val_policy_loss: 1.2863 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1492 - policy_loss: 1.2634 - value_loss: 0.8324 - val_loss: 2.1523 - val_policy_loss: 1.2866 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1476 - policy_loss: 1.2619 - value_loss: 0.8324 - val_loss: 2.1522 - val_policy_loss: 1.2867 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1454 - policy_loss: 1.2598 - value_loss: 0.8324 - val_loss: 2.1522 - val_policy_loss: 1.2867 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "90/90 [==============================] - 0s 4ms/step - loss: 2.1451 - policy_loss: 1.2597 - value_loss: 0.8324 - val_loss: 2.1523 - val_policy_loss: 1.2869 - val_value_loss: 0.8123 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 2.1464 - policy_loss: 1.2611 - value_loss: 0.8324 - val_loss: 2.1522 - val_policy_loss: 1.2870 - val_value_loss: 0.8123 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "fit_history = trainer.train(flatten_dataset, n_epochs=1000, batch_size=30, learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 129ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.5292804e-02, 3.7834185e-01, 6.2949868e-04, 2.4268795e-05,\n",
       "         1.5596172e-04, 8.0116923e-05, 1.5714881e-04, 6.8897156e-05,\n",
       "         6.0524940e-01]], dtype=float32),\n",
       " array([[0.07633218]], dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.predict(np.array([[0., 0., -1., -1., 1., -1., 1., 1., 0.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[7.0850857e-02, 8.1257693e-02, 5.1002884e-01, 1.2070657e-01,\n",
       "         2.4216896e-04, 4.6085939e-04, 1.1106054e-03, 9.6659914e-02,\n",
       "         1.1868248e-01]], dtype=float32),\n",
       " array([[0.07633218]], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.predict(np.array([[0., 0., 0., 0., -1., 1., -1., 0., 0.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('saved_model/tmp_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the self-playing dataset (2nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded_model = tf.keras.models.load_model(\"saved_model/alpha_zero_model_first_training_validation/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# speed test on 10 games\n",
    "start_time = time.time()\n",
    "trainer = Trainer(game = TicTacToe, mcts = MCTS, model=loaded_model)\n",
    "dataset = trainer.create_dataset(number_of_games=10, temperature=1)\n",
    "print(\"Running time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1175s -> ~30m for 100\n",
    "# 25*0.5 ~ 12hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROUNDS = 40\n",
    "N_GAMES_PER_JOB = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_fn(job_n, n):\n",
    "    \n",
    "    from libs.Trainer import Trainer\n",
    "    from libs.TicTacToe import TicTacToe\n",
    "    from libs.MCTS import MCTS\n",
    "    import tensorflow as tf\n",
    "    N_GAMES_PER_JOB = 25\n",
    "    STARTING_TEMPERATURE = 10.0\n",
    "    \n",
    "    model = tf.keras.models.load_model(\"saved_model/tmp_model\")\n",
    "    \n",
    "    trainer = Trainer(game = TicTacToe, mcts = MCTS, model=model)\n",
    "    \n",
    "    game_batch = trainer.create_dataset(number_of_games=N_GAMES_PER_JOB, temperature=STARTING_TEMPERATURE/n)\n",
    "    \n",
    "    return game_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#stored previous self-plays\n",
    "filename_data = \"4000_tictactoe_temperature_1_2nd_round.pickle\"\n",
    "if os.path.isfile(filename_data):\n",
    "    with open(filename_data, 'rb') as handle:\n",
    "        self_play_dataset = pickle.load(handle)\n",
    "    print(f\"Reusing {filename_data}\")\n",
    "else:\n",
    "    self_play_dataset = []\n",
    "    print(f\"Starting from empty self-play data\")\n",
    "\n",
    "model_tmp_filename = \"saved_model/tmp_model\"\n",
    "if os.path.isdir(model_tmp_filename):\n",
    "    model = tf.keras.models.load_model(model_tmp_filename)\n",
    "    print(f\"Starting with {model_tmp_filename}\")\n",
    "else:\n",
    "    model = tf.keras.models.load_model(\"saved_model/alpha_zero_model_first_training_validation/\")\n",
    "    print(f\"Starting with saved_model/alpha_zero_model_first_training_validation/\")\n",
    "\n",
    "model.save(model_tmp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time 1-th round: 784.0851500034332 seconds\n",
      "Epoch 1/50\n",
      "99/99 [==============================] - 2s 7ms/step - loss: 3.4331 - policy_loss: 1.8701 - value_loss: 1.4685 - val_loss: 2.8795 - val_policy_loss: 1.8861 - val_value_loss: 0.8879 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 2.5445 - policy_loss: 1.5845 - value_loss: 0.8573 - val_loss: 2.7668 - val_policy_loss: 1.7774 - val_value_loss: 0.8885 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.4404 - policy_loss: 1.4814 - value_loss: 0.8578 - val_loss: 2.4676 - val_policy_loss: 1.4782 - val_value_loss: 0.8879 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3856 - policy_loss: 1.4258 - value_loss: 0.8581 - val_loss: 2.4274 - val_policy_loss: 1.4353 - val_value_loss: 0.8896 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3574 - policy_loss: 1.3974 - value_loss: 0.8575 - val_loss: 2.3879 - val_policy_loss: 1.3967 - val_value_loss: 0.8880 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3485 - policy_loss: 1.3865 - value_loss: 0.8583 - val_loss: 2.3672 - val_policy_loss: 1.3734 - val_value_loss: 0.8895 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3319 - policy_loss: 1.3699 - value_loss: 0.8573 - val_loss: 2.3805 - val_policy_loss: 1.3880 - val_value_loss: 0.8879 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 2.3251 - policy_loss: 1.3629 - value_loss: 0.8574 - val_loss: 2.3637 - val_policy_loss: 1.3677 - val_value_loss: 0.8906 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 2.3222 - policy_loss: 1.3596 - value_loss: 0.8571 - val_loss: 2.4173 - val_policy_loss: 1.4232 - val_value_loss: 0.8888 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3146 - policy_loss: 1.3528 - value_loss: 0.8572 - val_loss: 2.4590 - val_policy_loss: 1.4641 - val_value_loss: 0.8903 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3163 - policy_loss: 1.3541 - value_loss: 0.8576 - val_loss: 2.3758 - val_policy_loss: 1.3821 - val_value_loss: 0.8885 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3115 - policy_loss: 1.3498 - value_loss: 0.8572 - val_loss: 2.3724 - val_policy_loss: 1.3803 - val_value_loss: 0.8886 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3088 - policy_loss: 1.3483 - value_loss: 0.8570 - val_loss: 2.6718 - val_policy_loss: 1.6809 - val_value_loss: 0.8878 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.3021 - policy_loss: 1.3431 - value_loss: 0.8570 - val_loss: 2.3625 - val_policy_loss: 1.3729 - val_value_loss: 0.8884 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2840 - policy_loss: 1.3274 - value_loss: 0.8571 - val_loss: 2.3179 - val_policy_loss: 1.3317 - val_value_loss: 0.8880 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2778 - policy_loss: 1.3238 - value_loss: 0.8575 - val_loss: 2.3145 - val_policy_loss: 1.3313 - val_value_loss: 0.8882 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2799 - policy_loss: 1.3282 - value_loss: 0.8571 - val_loss: 2.3181 - val_policy_loss: 1.3350 - val_value_loss: 0.8889 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 2.2626 - policy_loss: 1.3125 - value_loss: 0.8574 - val_loss: 2.3042 - val_policy_loss: 1.3256 - val_value_loss: 0.8881 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2560 - policy_loss: 1.3103 - value_loss: 0.8570 - val_loss: 2.2772 - val_policy_loss: 1.3015 - val_value_loss: 0.8888 - lr: 0.0070\n",
      "Epoch 20/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2494 - policy_loss: 1.3071 - value_loss: 0.8570 - val_loss: 2.2644 - val_policy_loss: 1.2925 - val_value_loss: 0.8882 - lr: 0.0064\n",
      "Epoch 21/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2393 - policy_loss: 1.3004 - value_loss: 0.8570 - val_loss: 2.2734 - val_policy_loss: 1.3042 - val_value_loss: 0.8889 - lr: 0.0058\n",
      "Epoch 22/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2270 - policy_loss: 1.2918 - value_loss: 0.8568 - val_loss: 2.2468 - val_policy_loss: 1.2810 - val_value_loss: 0.8894 - lr: 0.0052\n",
      "Epoch 23/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2213 - policy_loss: 1.2899 - value_loss: 0.8568 - val_loss: 2.2350 - val_policy_loss: 1.2734 - val_value_loss: 0.8886 - lr: 0.0046\n",
      "Epoch 24/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.2083 - policy_loss: 1.2801 - value_loss: 0.8568 - val_loss: 2.2172 - val_policy_loss: 1.2593 - val_value_loss: 0.8885 - lr: 0.0040\n",
      "Epoch 25/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1971 - policy_loss: 1.2728 - value_loss: 0.8567 - val_loss: 2.2118 - val_policy_loss: 1.2574 - val_value_loss: 0.8886 - lr: 0.0035\n",
      "Epoch 26/50\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 2.1895 - policy_loss: 1.2685 - value_loss: 0.8568 - val_loss: 2.2077 - val_policy_loss: 1.2567 - val_value_loss: 0.8884 - lr: 0.0030\n",
      "Epoch 27/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1835 - policy_loss: 1.2654 - value_loss: 0.8568 - val_loss: 2.2081 - val_policy_loss: 1.2597 - val_value_loss: 0.8884 - lr: 0.0026\n",
      "Epoch 28/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1775 - policy_loss: 1.2621 - value_loss: 0.8567 - val_loss: 2.2013 - val_policy_loss: 1.2555 - val_value_loss: 0.8883 - lr: 0.0022\n",
      "Epoch 29/50\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 2.1721 - policy_loss: 1.2590 - value_loss: 0.8567 - val_loss: 2.1981 - val_policy_loss: 1.2543 - val_value_loss: 0.8885 - lr: 0.0018\n",
      "Epoch 30/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1669 - policy_loss: 1.2558 - value_loss: 0.8567 - val_loss: 2.1917 - val_policy_loss: 1.2496 - val_value_loss: 0.8886 - lr: 0.0015\n",
      "Epoch 31/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1616 - policy_loss: 1.2522 - value_loss: 0.8566 - val_loss: 2.1904 - val_policy_loss: 1.2500 - val_value_loss: 0.8886 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1562 - policy_loss: 1.2483 - value_loss: 0.8567 - val_loss: 2.1880 - val_policy_loss: 1.2490 - val_value_loss: 0.8885 - lr: 9.9261e-04\n",
      "Epoch 33/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1525 - policy_loss: 1.2460 - value_loss: 0.8566 - val_loss: 2.1818 - val_policy_loss: 1.2439 - val_value_loss: 0.8886 - lr: 7.9659e-04\n",
      "Epoch 34/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1509 - policy_loss: 1.2454 - value_loss: 0.8566 - val_loss: 2.1827 - val_policy_loss: 1.2458 - val_value_loss: 0.8885 - lr: 6.3292e-04\n",
      "Epoch 35/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1474 - policy_loss: 1.2429 - value_loss: 0.8565 - val_loss: 2.1807 - val_policy_loss: 1.2446 - val_value_loss: 0.8885 - lr: 4.9787e-04\n",
      "Epoch 36/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1465 - policy_loss: 1.2427 - value_loss: 0.8565 - val_loss: 2.1793 - val_policy_loss: 1.2438 - val_value_loss: 0.8885 - lr: 3.8774e-04\n",
      "Epoch 37/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1436 - policy_loss: 1.2403 - value_loss: 0.8565 - val_loss: 2.1794 - val_policy_loss: 1.2444 - val_value_loss: 0.8885 - lr: 2.9897e-04\n",
      "Epoch 38/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1426 - policy_loss: 1.2397 - value_loss: 0.8565 - val_loss: 2.1782 - val_policy_loss: 1.2436 - val_value_loss: 0.8885 - lr: 2.2823e-04\n",
      "Epoch 39/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1423 - policy_loss: 1.2398 - value_loss: 0.8565 - val_loss: 2.1769 - val_policy_loss: 1.2426 - val_value_loss: 0.8885 - lr: 1.7249e-04\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1413 - policy_loss: 1.2390 - value_loss: 0.8565 - val_loss: 2.1768 - val_policy_loss: 1.2427 - val_value_loss: 0.8885 - lr: 1.2907e-04\n",
      "Epoch 41/50\n",
      "99/99 [==============================] - 1s 5ms/step - loss: 2.1403 - policy_loss: 1.2383 - value_loss: 0.8565 - val_loss: 2.1765 - val_policy_loss: 1.2426 - val_value_loss: 0.8885 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1408 - policy_loss: 1.2389 - value_loss: 0.8565 - val_loss: 2.1767 - val_policy_loss: 1.2430 - val_value_loss: 0.8884 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "99/99 [==============================] - 1s 6ms/step - loss: 2.1406 - policy_loss: 1.2389 - value_loss: 0.8565 - val_loss: 2.1770 - val_policy_loss: 1.2435 - val_value_loss: 0.8884 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1407 - policy_loss: 1.2392 - value_loss: 0.8565 - val_loss: 2.1760 - val_policy_loss: 1.2427 - val_value_loss: 0.8885 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1392 - policy_loss: 1.2379 - value_loss: 0.8565 - val_loss: 2.1761 - val_policy_loss: 1.2429 - val_value_loss: 0.8885 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1395 - policy_loss: 1.2383 - value_loss: 0.8565 - val_loss: 2.1766 - val_policy_loss: 1.2436 - val_value_loss: 0.8885 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1391 - policy_loss: 1.2381 - value_loss: 0.8565 - val_loss: 2.1760 - val_policy_loss: 1.2432 - val_value_loss: 0.8885 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1389 - policy_loss: 1.2382 - value_loss: 0.8565 - val_loss: 2.1753 - val_policy_loss: 1.2427 - val_value_loss: 0.8884 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1392 - policy_loss: 1.2386 - value_loss: 0.8565 - val_loss: 2.1748 - val_policy_loss: 1.2424 - val_value_loss: 0.8885 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "99/99 [==============================] - 0s 5ms/step - loss: 2.1384 - policy_loss: 1.2380 - value_loss: 0.8565 - val_loss: 2.1740 - val_policy_loss: 1.2417 - val_value_loss: 0.8885 - lr: 1.0000e-04\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time 2-th round: 699.984493970871 seconds\n",
      "Epoch 1/50\n",
      "144/144 [==============================] - 2s 6ms/step - loss: 2.3448 - policy_loss: 1.4013 - value_loss: 0.8670 - val_loss: 2.3434 - val_policy_loss: 1.3293 - val_value_loss: 0.9194 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3313 - policy_loss: 1.3598 - value_loss: 0.8680 - val_loss: 2.3308 - val_policy_loss: 1.3047 - val_value_loss: 0.9188 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3259 - policy_loss: 1.3467 - value_loss: 0.8681 - val_loss: 2.3273 - val_policy_loss: 1.2967 - val_value_loss: 0.9191 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3148 - policy_loss: 1.3349 - value_loss: 0.8686 - val_loss: 2.3572 - val_policy_loss: 1.3267 - val_value_loss: 0.9202 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3227 - policy_loss: 1.3388 - value_loss: 0.8679 - val_loss: 2.2913 - val_policy_loss: 1.2588 - val_value_loss: 0.9195 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3149 - policy_loss: 1.3305 - value_loss: 0.8687 - val_loss: 2.3088 - val_policy_loss: 1.2762 - val_value_loss: 0.9193 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3170 - policy_loss: 1.3345 - value_loss: 0.8675 - val_loss: 2.3728 - val_policy_loss: 1.3402 - val_value_loss: 0.9193 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3100 - policy_loss: 1.3283 - value_loss: 0.8673 - val_loss: 2.2851 - val_policy_loss: 1.2544 - val_value_loss: 0.9191 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3229 - policy_loss: 1.3381 - value_loss: 0.8679 - val_loss: 2.2965 - val_policy_loss: 1.2604 - val_value_loss: 0.9197 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "144/144 [==============================] - 1s 6ms/step - loss: 2.3048 - policy_loss: 1.3223 - value_loss: 0.8676 - val_loss: 2.3183 - val_policy_loss: 1.2868 - val_value_loss: 0.9201 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "144/144 [==============================] - 1s 6ms/step - loss: 2.3051 - policy_loss: 1.3247 - value_loss: 0.8672 - val_loss: 2.2816 - val_policy_loss: 1.2526 - val_value_loss: 0.9192 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3078 - policy_loss: 1.3271 - value_loss: 0.8675 - val_loss: 2.2878 - val_policy_loss: 1.2586 - val_value_loss: 0.9190 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3061 - policy_loss: 1.3279 - value_loss: 0.8678 - val_loss: 2.3058 - val_policy_loss: 1.2781 - val_value_loss: 0.9189 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.3002 - policy_loss: 1.3236 - value_loss: 0.8679 - val_loss: 2.2794 - val_policy_loss: 1.2550 - val_value_loss: 0.9191 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2877 - policy_loss: 1.3146 - value_loss: 0.8677 - val_loss: 2.2588 - val_policy_loss: 1.2343 - val_value_loss: 0.9221 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2864 - policy_loss: 1.3142 - value_loss: 0.8678 - val_loss: 2.2740 - val_policy_loss: 1.2537 - val_value_loss: 0.9190 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2755 - policy_loss: 1.3069 - value_loss: 0.8678 - val_loss: 2.2707 - val_policy_loss: 1.2515 - val_value_loss: 0.9223 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2604 - policy_loss: 1.2989 - value_loss: 0.8677 - val_loss: 2.2802 - val_policy_loss: 1.2696 - val_value_loss: 0.9194 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2522 - policy_loss: 1.2943 - value_loss: 0.8679 - val_loss: 2.2370 - val_policy_loss: 1.2315 - val_value_loss: 0.9189 - lr: 0.0070\n",
      "Epoch 20/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2408 - policy_loss: 1.2887 - value_loss: 0.8674 - val_loss: 2.2446 - val_policy_loss: 1.2437 - val_value_loss: 0.9189 - lr: 0.0064\n",
      "Epoch 21/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2316 - policy_loss: 1.2840 - value_loss: 0.8674 - val_loss: 2.2235 - val_policy_loss: 1.2269 - val_value_loss: 0.9188 - lr: 0.0058\n",
      "Epoch 22/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2205 - policy_loss: 1.2764 - value_loss: 0.8675 - val_loss: 2.1877 - val_policy_loss: 1.1943 - val_value_loss: 0.9194 - lr: 0.0052\n",
      "Epoch 23/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2146 - policy_loss: 1.2739 - value_loss: 0.8676 - val_loss: 2.1933 - val_policy_loss: 1.2020 - val_value_loss: 0.9204 - lr: 0.0046\n",
      "Epoch 24/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.2126 - policy_loss: 1.2742 - value_loss: 0.8677 - val_loss: 2.1801 - val_policy_loss: 1.1921 - val_value_loss: 0.9193 - lr: 0.0040\n",
      "Epoch 25/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1926 - policy_loss: 1.2585 - value_loss: 0.8675 - val_loss: 2.2015 - val_policy_loss: 1.2178 - val_value_loss: 0.9192 - lr: 0.0035\n",
      "Epoch 26/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1896 - policy_loss: 1.2585 - value_loss: 0.8676 - val_loss: 2.1736 - val_policy_loss: 1.1928 - val_value_loss: 0.9190 - lr: 0.0030\n",
      "Epoch 27/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1795 - policy_loss: 1.2514 - value_loss: 0.8674 - val_loss: 2.2207 - val_policy_loss: 1.2424 - val_value_loss: 0.9192 - lr: 0.0026\n",
      "Epoch 28/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1702 - policy_loss: 1.2452 - value_loss: 0.8672 - val_loss: 2.1674 - val_policy_loss: 1.1920 - val_value_loss: 0.9190 - lr: 0.0022\n",
      "Epoch 29/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1651 - policy_loss: 1.2425 - value_loss: 0.8672 - val_loss: 2.1517 - val_policy_loss: 1.1787 - val_value_loss: 0.9190 - lr: 0.0018\n",
      "Epoch 30/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1606 - policy_loss: 1.2401 - value_loss: 0.8672 - val_loss: 2.1353 - val_policy_loss: 1.1640 - val_value_loss: 0.9190 - lr: 0.0015\n",
      "Epoch 31/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1573 - policy_loss: 1.2386 - value_loss: 0.8672 - val_loss: 2.1411 - val_policy_loss: 1.1712 - val_value_loss: 0.9191 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1530 - policy_loss: 1.2357 - value_loss: 0.8671 - val_loss: 2.1362 - val_policy_loss: 1.1675 - val_value_loss: 0.9192 - lr: 9.9261e-04\n",
      "Epoch 33/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1491 - policy_loss: 1.2329 - value_loss: 0.8672 - val_loss: 2.1312 - val_policy_loss: 1.1636 - val_value_loss: 0.9192 - lr: 7.9659e-04\n",
      "Epoch 34/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1459 - policy_loss: 1.2307 - value_loss: 0.8671 - val_loss: 2.1365 - val_policy_loss: 1.1699 - val_value_loss: 0.9191 - lr: 6.3292e-04\n",
      "Epoch 35/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1438 - policy_loss: 1.2294 - value_loss: 0.8671 - val_loss: 2.1384 - val_policy_loss: 1.1723 - val_value_loss: 0.9192 - lr: 4.9787e-04\n",
      "Epoch 36/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1406 - policy_loss: 1.2269 - value_loss: 0.8671 - val_loss: 2.1355 - val_policy_loss: 1.1701 - val_value_loss: 0.9191 - lr: 3.8774e-04\n",
      "Epoch 37/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1400 - policy_loss: 1.2268 - value_loss: 0.8671 - val_loss: 2.1322 - val_policy_loss: 1.1672 - val_value_loss: 0.9191 - lr: 2.9897e-04\n",
      "Epoch 38/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1378 - policy_loss: 1.2251 - value_loss: 0.8671 - val_loss: 2.1332 - val_policy_loss: 1.1686 - val_value_loss: 0.9191 - lr: 2.2823e-04\n",
      "Epoch 39/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1383 - policy_loss: 1.2258 - value_loss: 0.8671 - val_loss: 2.1302 - val_policy_loss: 1.1658 - val_value_loss: 0.9191 - lr: 1.7249e-04\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1372 - policy_loss: 1.2250 - value_loss: 0.8671 - val_loss: 2.1308 - val_policy_loss: 1.1666 - val_value_loss: 0.9191 - lr: 1.2907e-04\n",
      "Epoch 41/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1362 - policy_loss: 1.2241 - value_loss: 0.8671 - val_loss: 2.1302 - val_policy_loss: 1.1662 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1367 - policy_loss: 1.2248 - value_loss: 0.8671 - val_loss: 2.1301 - val_policy_loss: 1.1662 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1363 - policy_loss: 1.2246 - value_loss: 0.8671 - val_loss: 2.1286 - val_policy_loss: 1.1649 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1366 - policy_loss: 1.2250 - value_loss: 0.8671 - val_loss: 2.1290 - val_policy_loss: 1.1655 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1362 - policy_loss: 1.2248 - value_loss: 0.8671 - val_loss: 2.1284 - val_policy_loss: 1.1651 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1347 - policy_loss: 1.2234 - value_loss: 0.8671 - val_loss: 2.1290 - val_policy_loss: 1.1658 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1344 - policy_loss: 1.2233 - value_loss: 0.8671 - val_loss: 2.1275 - val_policy_loss: 1.1644 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1356 - policy_loss: 1.2247 - value_loss: 0.8671 - val_loss: 2.1269 - val_policy_loss: 1.1640 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1344 - policy_loss: 1.2236 - value_loss: 0.8671 - val_loss: 2.1276 - val_policy_loss: 1.1648 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 2.1342 - policy_loss: 1.2236 - value_loss: 0.8671 - val_loss: 2.1267 - val_policy_loss: 1.1641 - val_value_loss: 0.9191 - lr: 1.0000e-04\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time 3-th round: 651.7305974960327 seconds\n",
      "Epoch 1/50\n",
      "187/187 [==============================] - 2s 6ms/step - loss: 2.2667 - policy_loss: 1.3297 - value_loss: 0.8730 - val_loss: 2.2512 - val_policy_loss: 1.2460 - val_value_loss: 0.9315 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2534 - policy_loss: 1.3042 - value_loss: 0.8723 - val_loss: 2.2781 - val_policy_loss: 1.2674 - val_value_loss: 0.9305 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2594 - policy_loss: 1.3050 - value_loss: 0.8722 - val_loss: 2.3810 - val_policy_loss: 1.3651 - val_value_loss: 0.9314 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2543 - policy_loss: 1.2986 - value_loss: 0.8721 - val_loss: 2.2599 - val_policy_loss: 1.2438 - val_value_loss: 0.9312 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2593 - policy_loss: 1.3011 - value_loss: 0.8728 - val_loss: 2.2731 - val_policy_loss: 1.2552 - val_value_loss: 0.9305 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2631 - policy_loss: 1.3025 - value_loss: 0.8727 - val_loss: 2.2548 - val_policy_loss: 1.2315 - val_value_loss: 0.9349 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2620 - policy_loss: 1.3017 - value_loss: 0.8723 - val_loss: 2.2512 - val_policy_loss: 1.2323 - val_value_loss: 0.9305 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2609 - policy_loss: 1.3001 - value_loss: 0.8720 - val_loss: 2.2395 - val_policy_loss: 1.2197 - val_value_loss: 0.9315 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2604 - policy_loss: 1.2994 - value_loss: 0.8723 - val_loss: 2.2687 - val_policy_loss: 1.2501 - val_value_loss: 0.9312 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2605 - policy_loss: 1.3003 - value_loss: 0.8724 - val_loss: 2.2693 - val_policy_loss: 1.2499 - val_value_loss: 0.9305 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2605 - policy_loss: 1.2989 - value_loss: 0.8729 - val_loss: 2.2356 - val_policy_loss: 1.2149 - val_value_loss: 0.9325 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2566 - policy_loss: 1.2979 - value_loss: 0.8718 - val_loss: 2.2421 - val_policy_loss: 1.2252 - val_value_loss: 0.9305 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2414 - policy_loss: 1.2856 - value_loss: 0.8718 - val_loss: 2.2270 - val_policy_loss: 1.2146 - val_value_loss: 0.9308 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2484 - policy_loss: 1.2942 - value_loss: 0.8726 - val_loss: 2.2339 - val_policy_loss: 1.2195 - val_value_loss: 0.9318 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2386 - policy_loss: 1.2854 - value_loss: 0.8721 - val_loss: 2.2209 - val_policy_loss: 1.2079 - val_value_loss: 0.9326 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2340 - policy_loss: 1.2833 - value_loss: 0.8720 - val_loss: 2.2601 - val_policy_loss: 1.2470 - val_value_loss: 0.9356 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2295 - policy_loss: 1.2809 - value_loss: 0.8726 - val_loss: 2.2168 - val_policy_loss: 1.2107 - val_value_loss: 0.9307 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2213 - policy_loss: 1.2752 - value_loss: 0.8720 - val_loss: 2.2367 - val_policy_loss: 1.2310 - val_value_loss: 0.9330 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2108 - policy_loss: 1.2678 - value_loss: 0.8725 - val_loss: 2.1951 - val_policy_loss: 1.1959 - val_value_loss: 0.9305 - lr: 0.0070\n",
      "Epoch 20/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.2028 - policy_loss: 1.2640 - value_loss: 0.8720 - val_loss: 2.1998 - val_policy_loss: 1.2035 - val_value_loss: 0.9311 - lr: 0.0064\n",
      "Epoch 21/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1985 - policy_loss: 1.2629 - value_loss: 0.8718 - val_loss: 2.1901 - val_policy_loss: 1.1969 - val_value_loss: 0.9306 - lr: 0.0058\n",
      "Epoch 22/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1906 - policy_loss: 1.2575 - value_loss: 0.8719 - val_loss: 2.1965 - val_policy_loss: 1.2055 - val_value_loss: 0.9311 - lr: 0.0052\n",
      "Epoch 23/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1837 - policy_loss: 1.2534 - value_loss: 0.8719 - val_loss: 2.1893 - val_policy_loss: 1.2003 - val_value_loss: 0.9319 - lr: 0.0046\n",
      "Epoch 24/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1735 - policy_loss: 1.2461 - value_loss: 0.8717 - val_loss: 2.1569 - val_policy_loss: 1.1709 - val_value_loss: 0.9318 - lr: 0.0040\n",
      "Epoch 25/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1663 - policy_loss: 1.2415 - value_loss: 0.8720 - val_loss: 2.1534 - val_policy_loss: 1.1706 - val_value_loss: 0.9313 - lr: 0.0035\n",
      "Epoch 26/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1586 - policy_loss: 1.2367 - value_loss: 0.8718 - val_loss: 2.1404 - val_policy_loss: 1.1596 - val_value_loss: 0.9320 - lr: 0.0030\n",
      "Epoch 27/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1509 - policy_loss: 1.2315 - value_loss: 0.8717 - val_loss: 2.1273 - val_policy_loss: 1.1499 - val_value_loss: 0.9308 - lr: 0.0026\n",
      "Epoch 28/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1458 - policy_loss: 1.2283 - value_loss: 0.8719 - val_loss: 2.1305 - val_policy_loss: 1.1548 - val_value_loss: 0.9310 - lr: 0.0022\n",
      "Epoch 29/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1414 - policy_loss: 1.2258 - value_loss: 0.8717 - val_loss: 2.1384 - val_policy_loss: 1.1641 - val_value_loss: 0.9313 - lr: 0.0018\n",
      "Epoch 30/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1363 - policy_loss: 1.2223 - value_loss: 0.8717 - val_loss: 2.1211 - val_policy_loss: 1.1486 - val_value_loss: 0.9310 - lr: 0.0015\n",
      "Epoch 31/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1323 - policy_loss: 1.2197 - value_loss: 0.8717 - val_loss: 2.1198 - val_policy_loss: 1.1481 - val_value_loss: 0.9315 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1282 - policy_loss: 1.2169 - value_loss: 0.8716 - val_loss: 2.1169 - val_policy_loss: 1.1464 - val_value_loss: 0.9314 - lr: 9.9261e-04\n",
      "Epoch 33/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1253 - policy_loss: 1.2149 - value_loss: 0.8717 - val_loss: 2.1226 - val_policy_loss: 1.1529 - val_value_loss: 0.9314 - lr: 7.9659e-04\n",
      "Epoch 34/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1242 - policy_loss: 1.2147 - value_loss: 0.8716 - val_loss: 2.1126 - val_policy_loss: 1.1438 - val_value_loss: 0.9313 - lr: 6.3292e-04\n",
      "Epoch 35/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1224 - policy_loss: 1.2135 - value_loss: 0.8716 - val_loss: 2.1152 - val_policy_loss: 1.1469 - val_value_loss: 0.9312 - lr: 4.9787e-04\n",
      "Epoch 36/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1207 - policy_loss: 1.2123 - value_loss: 0.8716 - val_loss: 2.1111 - val_policy_loss: 1.1433 - val_value_loss: 0.9312 - lr: 3.8774e-04\n",
      "Epoch 37/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1185 - policy_loss: 1.2105 - value_loss: 0.8716 - val_loss: 2.1117 - val_policy_loss: 1.1443 - val_value_loss: 0.9313 - lr: 2.9897e-04\n",
      "Epoch 38/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1181 - policy_loss: 1.2105 - value_loss: 0.8716 - val_loss: 2.1100 - val_policy_loss: 1.1428 - val_value_loss: 0.9312 - lr: 2.2823e-04\n",
      "Epoch 39/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1168 - policy_loss: 1.2094 - value_loss: 0.8716 - val_loss: 2.1091 - val_policy_loss: 1.1421 - val_value_loss: 0.9312 - lr: 1.7249e-04\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1174 - policy_loss: 1.2101 - value_loss: 0.8716 - val_loss: 2.1097 - val_policy_loss: 1.1429 - val_value_loss: 0.9312 - lr: 1.2907e-04\n",
      "Epoch 41/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1150 - policy_loss: 1.2080 - value_loss: 0.8716 - val_loss: 2.1090 - val_policy_loss: 1.1423 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1144 - policy_loss: 1.2075 - value_loss: 0.8716 - val_loss: 2.1089 - val_policy_loss: 1.1423 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1143 - policy_loss: 1.2075 - value_loss: 0.8716 - val_loss: 2.1081 - val_policy_loss: 1.1416 - val_value_loss: 0.9312 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1153 - policy_loss: 1.2086 - value_loss: 0.8716 - val_loss: 2.1081 - val_policy_loss: 1.1418 - val_value_loss: 0.9312 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1152 - policy_loss: 1.2086 - value_loss: 0.8716 - val_loss: 2.1083 - val_policy_loss: 1.1421 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1145 - policy_loss: 1.2081 - value_loss: 0.8716 - val_loss: 2.1077 - val_policy_loss: 1.1416 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1143 - policy_loss: 1.2079 - value_loss: 0.8716 - val_loss: 2.1069 - val_policy_loss: 1.1409 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1138 - policy_loss: 1.2075 - value_loss: 0.8716 - val_loss: 2.1066 - val_policy_loss: 1.1407 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1132 - policy_loss: 1.2071 - value_loss: 0.8716 - val_loss: 2.1063 - val_policy_loss: 1.1405 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 2.1136 - policy_loss: 1.2077 - value_loss: 0.8716 - val_loss: 2.1067 - val_policy_loss: 1.1411 - val_value_loss: 0.9313 - lr: 1.0000e-04\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time 4-th round: 645.3469252586365 seconds\n",
      "Epoch 1/50\n",
      "232/232 [==============================] - 3s 6ms/step - loss: 2.2150 - policy_loss: 1.2969 - value_loss: 0.8689 - val_loss: 2.0786 - val_policy_loss: 1.1835 - val_value_loss: 0.8379 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2167 - policy_loss: 1.2854 - value_loss: 0.8690 - val_loss: 2.1294 - val_policy_loss: 1.2313 - val_value_loss: 0.8324 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2178 - policy_loss: 1.2808 - value_loss: 0.8688 - val_loss: 2.1134 - val_policy_loss: 1.2111 - val_value_loss: 0.8323 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2104 - policy_loss: 1.2711 - value_loss: 0.8689 - val_loss: 2.1105 - val_policy_loss: 1.2057 - val_value_loss: 0.8334 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2156 - policy_loss: 1.2749 - value_loss: 0.8686 - val_loss: 2.0888 - val_policy_loss: 1.1819 - val_value_loss: 0.8341 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2122 - policy_loss: 1.2704 - value_loss: 0.8690 - val_loss: 2.1036 - val_policy_loss: 1.1977 - val_value_loss: 0.8322 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2163 - policy_loss: 1.2736 - value_loss: 0.8688 - val_loss: 2.1156 - val_policy_loss: 1.2083 - val_value_loss: 0.8321 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2246 - policy_loss: 1.2795 - value_loss: 0.8687 - val_loss: 2.1217 - val_policy_loss: 1.2136 - val_value_loss: 0.8321 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2129 - policy_loss: 1.2689 - value_loss: 0.8686 - val_loss: 2.1032 - val_policy_loss: 1.1962 - val_value_loss: 0.8322 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2167 - policy_loss: 1.2728 - value_loss: 0.8688 - val_loss: 2.0840 - val_policy_loss: 1.1765 - val_value_loss: 0.8325 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "232/232 [==============================] - 1s 5ms/step - loss: 2.2137 - policy_loss: 1.2704 - value_loss: 0.8688 - val_loss: 2.1402 - val_policy_loss: 1.2336 - val_value_loss: 0.8320 - lr: 0.0100\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    }
   ],
   "source": [
    "self_play_dataset = flatten_dataset\n",
    "\n",
    "for n in range(N_ROUNDS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    ctx = mp.get_context(\"spawn\")\n",
    "    \n",
    "    pool = ctx.Pool(n_cores)\n",
    "    \n",
    "    args = list(zip(range(n_cores),[n+1]*n_cores))\n",
    "    \n",
    "    round_dataset = pool.starmap(parallel_fn, args)\n",
    "    print(f\"Running time {n+1}-th round: {time.time() - start_time} seconds\")\n",
    "    \n",
    "    flatten_round_dataset = []\n",
    "    for batch in round_dataset:\n",
    "        flatten_round_dataset += batch\n",
    "    self_play_dataset += flatten_round_dataset\n",
    "    \n",
    "    trainer = Trainer(game = TicTacToe, mcts = MCTS, model=model)\n",
    "    fit_history = trainer.train(self_play_dataset, n_epochs=50, batch_size=50, learning_rate=1e-2)\n",
    "    \n",
    "    trainer.model.save(\"saved_model/tmp_model\")\n",
    "    \n",
    "    with open(\"selfplay_data.pickle\", \"wb\") as fp:\n",
    "        pickle.dump(self_play_dataset, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TicTacToe.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
