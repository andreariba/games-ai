{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1' # only for Intel CPU\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import multiprocess as mp\n",
    "from multiprocess.managers import SyncManager\n",
    "import tensorflow as tf\n",
    "from libs.FourInARow import FourInARow\n",
    "from libs.model import create_az_model, CachedModel\n",
    "from libs.Trainer import Trainer\n",
    "from libs.MCTS import MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Number of cores]: 16\n"
     ]
    }
   ],
   "source": [
    "n_cores = mp.cpu_count()\n",
    "print(f\"[Number of cores]: {n_cores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test FourInARow engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12, 13],\n",
       "       [14, 15, 16, 17, 18, 19, 20],\n",
       "       [21, 22, 23, 24, 25, 26, 27],\n",
       "       [28, 29, 30, 31, 32, 33, 34],\n",
       "       [35, 36, 37, 38, 39, 40, 41]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(42).reshape(6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiar = FourInARow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assert the action size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert fiar.get_action_size()==7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assert the available actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (fiar.get_available_actions(np.zeros(42))==np.ones(7)).all()\n",
    "assert (fiar.get_reward_for_player(np.zeros(42),1)==None)\n",
    "assert (fiar.get_reward_for_player(np.zeros(42),-1)==None)\n",
    "fiar.play(np.zeros(42))\n",
    "assert (fiar.check_if_winner(1)==False )\n",
    "assert (fiar.check_if_winner(-1)==False )\n",
    "\n",
    "\n",
    "\n",
    "assert (fiar.get_available_actions(np.ones(42))==np.zeros(7)).all()\n",
    "assert (fiar.get_reward_for_player(np.ones(42),1)==1)\n",
    "assert (fiar.get_reward_for_player(np.ones(42),-1)==-1)\n",
    "fiar.play(-1*np.ones(42))\n",
    "assert (fiar.check_if_winner(1)==False )\n",
    "assert (fiar.check_if_winner(-1)==True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "case = np.zeros(42)\n",
    "case[-7:] = 1\n",
    "\n",
    "columns_to_fill = [0,3]\n",
    "for c in columns_to_fill:\n",
    "    case[c::7] = 1\n",
    "\n",
    "\n",
    "solution = np.ones(7)\n",
    "solution[columns_to_fill] = 0\n",
    "\n",
    "print(case.reshape(6,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (fiar.get_available_actions(case)==solution).all()\n",
    "\n",
    "fiar.play(case)\n",
    "\n",
    "assert (fiar.check_if_winner(1)==True )\n",
    "assert (fiar.check_if_winner(-1)==False )\n",
    "assert (fiar.get_reward_for_player(np.ones(42),1)==1)\n",
    "assert (fiar.get_reward_for_player(np.ones(42),-1)==-1)\n",
    "\n",
    "assert (fiar.get_board_from_player(player=1)==case).all()\n",
    "assert (fiar.get_board_from_player(player=-1)==-case).all()\n",
    "\n",
    "fiar.play(case*-1)\n",
    "\n",
    "assert (fiar.check_if_winner(1)==False )\n",
    "assert (fiar.check_if_winner(-1)==True )\n",
    "assert (fiar.get_reward_for_player(-np.ones(42),1)==-1)\n",
    "assert (fiar.get_reward_for_player(-np.ones(42),-1)==1)\n",
    "\n",
    "assert (fiar.get_board_from_player(player=1)==-case).all()\n",
    "assert (fiar.get_board_from_player(player=-1)==case).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1.  1.  0.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1.  1.  0.  1.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1.  1.  0.  1. -1.]]\n",
      "Last board for player 1\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0. -1.  1.  0.  1. -1.]]\n",
      "Last board for player -1\n",
      "[[-0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0.]\n",
      " [-0. -0. -0. -0. -0. -0. -0.]\n",
      " [ 1. -0. -0. -0. -0. -0. -0.]\n",
      " [-1. -0.  1. -1. -0. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "next_player = 1\n",
    "next_state, next_player = fiar.next_state(board=np.zeros(42), player=next_player, action=0)\n",
    "print(next_state.reshape(6,7))\n",
    "\n",
    "next_state, next_player = fiar.next_state(board=next_state, player=next_player, action=0)\n",
    "print(next_state.reshape(6,7))\n",
    "\n",
    "next_state, next_player = fiar.next_state(board=next_state, player=next_player, action=3)\n",
    "print(next_state.reshape(6,7))\n",
    "\n",
    "next_state, next_player = fiar.next_state(board=next_state, player=next_player, action=2)\n",
    "print(next_state.reshape(6,7))\n",
    "\n",
    "next_state, next_player = fiar.next_state(board=next_state, player=next_player, action=5)\n",
    "print(next_state.reshape(6,7))\n",
    "\n",
    "next_state, next_player = fiar.next_state(board=next_state, player=next_player, action=6)\n",
    "print(next_state.reshape(6,7))\n",
    "\n",
    "print(\"Last board for player 1\")\n",
    "print(fiar.get_board_from_player(player=1).reshape(6,7))\n",
    "print(\"Last board for player -1\")\n",
    "print(fiar.get_board_from_player(player=-1).reshape(6,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_az_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = fiar.get_board_from_player(player=-1)[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       " array([[0.14285715, 0.14285715, 0.14285715, 0.14285715, 0.14285715,\n",
       "         0.14285715, 0.14285715]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts = MCTS(game=FourInARow(), n_simulations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.zeros(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = mcts.run(model=None, state=state, player=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State:\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "Player:1\n",
       "Value:0.0\n",
       "Leaf:False\n",
       "Visits:100\n",
       "Children:\n",
       " -0: prior=0.14285714285714285\n",
       " -1: prior=0.14285714285714285\n",
       " -2: prior=0.14285714285714285\n",
       " -3: prior=0.14285714285714285\n",
       " -4: prior=0.14285714285714285\n",
       " -5: prior=0.14285714285714285\n",
       " -6: prior=0.14285714285714285"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State:\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
       "Player:-1\n",
       "Value:0.0\n",
       "Leaf:False\n",
       "Visits:14\n",
       "Children:\n",
       " -0: prior=0.14285714285714285\n",
       " -1: prior=0.14285714285714285\n",
       " -2: prior=0.14285714285714285\n",
       " -3: prior=0.14285714285714285\n",
       " -4: prior=0.14285714285714285\n",
       " -5: prior=0.14285714285714285\n",
       " -6: prior=0.14285714285714285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: State:\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.\n",
       "   0.  1.  0.  0.  0.  0.]\n",
       " Player:1\n",
       " Value:0.0\n",
       " Leaf:False\n",
       " Visits:2\n",
       " Children:\n",
       "  -0: prior=0.14285714285714285\n",
       "  -1: prior=0.14285714285714285\n",
       "  -2: prior=0.14285714285714285\n",
       "  -3: prior=0.14285714285714285\n",
       "  -4: prior=0.14285714285714285\n",
       "  -5: prior=0.14285714285714285\n",
       "  -6: prior=0.14285714285714285,\n",
       " 1: State:\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "  -1.  1.  0.  0.  0.  0.]\n",
       " Player:1\n",
       " Value:0.0\n",
       " Leaf:False\n",
       " Visits:2\n",
       " Children:\n",
       "  -0: prior=0.14285714285714285\n",
       "  -1: prior=0.14285714285714285\n",
       "  -2: prior=0.14285714285714285\n",
       "  -3: prior=0.14285714285714285\n",
       "  -4: prior=0.14285714285714285\n",
       "  -5: prior=0.14285714285714285\n",
       "  -6: prior=0.14285714285714285,\n",
       " 2: State:\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.  0.\n",
       "   0.  1.  0.  0.  0.  0.]\n",
       " Player:1\n",
       " Value:0.0\n",
       " Leaf:False\n",
       " Visits:2\n",
       " Children:\n",
       "  -0: prior=0.14285714285714285\n",
       "  -1: prior=0.14285714285714285\n",
       "  -2: prior=0.14285714285714285\n",
       "  -3: prior=0.14285714285714285\n",
       "  -4: prior=0.14285714285714285\n",
       "  -5: prior=0.14285714285714285\n",
       "  -6: prior=0.14285714285714285,\n",
       " 3: State:\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  1. -1.  0.  0.  0.]\n",
       " Player:1\n",
       " Value:0.0\n",
       " Leaf:False\n",
       " Visits:2\n",
       " Children:\n",
       "  -0: prior=0.14285714285714285\n",
       "  -1: prior=0.14285714285714285\n",
       "  -2: prior=0.14285714285714285\n",
       "  -3: prior=0.14285714285714285\n",
       "  -4: prior=0.14285714285714285\n",
       "  -5: prior=0.14285714285714285\n",
       "  -6: prior=0.14285714285714285,\n",
       " 4: State:\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  1.  0. -1.  0.  0.]\n",
       " Player:1\n",
       " Value:0.0\n",
       " Leaf:False\n",
       " Visits:1\n",
       " Children:\n",
       "  -0: prior=0.14285714285714285\n",
       "  -1: prior=0.14285714285714285\n",
       "  -2: prior=0.14285714285714285\n",
       "  -3: prior=0.14285714285714285\n",
       "  -4: prior=0.14285714285714285\n",
       "  -5: prior=0.14285714285714285\n",
       "  -6: prior=0.14285714285714285,\n",
       " 5: State:\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  1.  0.  0. -1.  0.]\n",
       " Player:1\n",
       " Value:0.0\n",
       " Leaf:False\n",
       " Visits:2\n",
       " Children:\n",
       "  -0: prior=0.14285714285714285\n",
       "  -1: prior=0.14285714285714285\n",
       "  -2: prior=0.14285714285714285\n",
       "  -3: prior=0.14285714285714285\n",
       "  -4: prior=0.14285714285714285\n",
       "  -5: prior=0.14285714285714285\n",
       "  -6: prior=0.14285714285714285,\n",
       " 6: State:\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
       "   0.  1.  0.  0.  0. -1.]\n",
       " Player:1\n",
       " Value:0.0\n",
       " Leaf:False\n",
       " Visits:2\n",
       " Children:\n",
       "  -0: prior=0.14285714285714285\n",
       "  -1: prior=0.14285714285714285\n",
       "  -2: prior=0.14285714285714285\n",
       "  -3: prior=0.14285714285714285\n",
       "  -4: prior=0.14285714285714285\n",
       "  -5: prior=0.14285714285714285\n",
       "  -6: prior=0.14285714285714285}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.children[2].children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING_TEMPERATURE = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 4.005084276199341 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainer = Trainer(game = FourInARow, mcts = MCTS, model=None)\n",
    "dataset = trainer.create_dataset(number_of_games=2, temperature=STARTING_TEMPERATURE)\n",
    "print(\"Running time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelizing the code to speed up the generation of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_fn(n):\n",
    "    from libs.Trainer import Trainer\n",
    "    from libs.FourInARow import FourInARow\n",
    "    from libs.MCTS import MCTS\n",
    "    N_GAMES_PER_JOB = 25\n",
    "    STARTING_TEMPERATURE = 10.0\n",
    "    trainer = Trainer(game = FourInARow, mcts = MCTS, model=None)\n",
    "    game_batch = trainer.create_dataset(number_of_games=N_GAMES_PER_JOB, temperature=STARTING_TEMPERATURE)\n",
    "    return game_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time: 139.8901174068451 seconds\n"
     ]
    }
   ],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "start_time = time.time()\n",
    "ctx = mp.get_context(\"spawn\")\n",
    "pool = ctx.Pool(n_cores)\n",
    "dataset = pool.map(parallel_fn, range(n_cores))\n",
    "print(\"Running time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flatten_dataset = []\n",
    "for batch in dataset:\n",
    "    flatten_dataset += batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7692"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(game = FourInARow, mcts = MCTS, model=create_az_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "231/231 [==============================] - 4s 11ms/step - loss: 4.2212 - policy_loss: 2.0336 - value_loss: 1.9404 - val_loss: 3.8646 - val_policy_loss: 1.9442 - val_value_loss: 1.7371 - lr: 0.0100\n",
      "Epoch 2/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 3.9931 - policy_loss: 1.9220 - value_loss: 1.9388 - val_loss: 4.0074 - val_policy_loss: 1.9677 - val_value_loss: 1.9428 - lr: 0.0100\n",
      "Epoch 3/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 3.9364 - policy_loss: 1.9055 - value_loss: 1.9399 - val_loss: 3.9755 - val_policy_loss: 1.9396 - val_value_loss: 1.9429 - lr: 0.0100\n",
      "Epoch 4/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 3.9348 - policy_loss: 1.8847 - value_loss: 1.9369 - val_loss: 4.7572 - val_policy_loss: 2.4777 - val_value_loss: 2.0571 - lr: 0.0100\n",
      "Epoch 5/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 3.2006 - policy_loss: 1.8890 - value_loss: 1.0439 - val_loss: 3.0971 - val_policy_loss: 1.9174 - val_value_loss: 0.9999 - lr: 0.0100\n",
      "Epoch 6/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 3.0339 - policy_loss: 1.8480 - value_loss: 1.0007 - val_loss: 3.0764 - val_policy_loss: 1.8864 - val_value_loss: 1.0013 - lr: 0.0100\n",
      "Epoch 7/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 3.0260 - policy_loss: 1.8280 - value_loss: 1.0008 - val_loss: 3.3198 - val_policy_loss: 2.1177 - val_value_loss: 0.9993 - lr: 0.0100\n",
      "Epoch 8/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 3.0405 - policy_loss: 1.8156 - value_loss: 1.0001 - val_loss: 3.1035 - val_policy_loss: 1.8596 - val_value_loss: 1.0003 - lr: 0.0100\n",
      "Epoch 9/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 3.0477 - policy_loss: 1.8063 - value_loss: 0.9995 - val_loss: 3.0918 - val_policy_loss: 1.8456 - val_value_loss: 0.9996 - lr: 0.0100\n",
      "Epoch 10/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 3.0474 - policy_loss: 1.7952 - value_loss: 1.0004 - val_loss: 3.0761 - val_policy_loss: 1.8322 - val_value_loss: 0.9992 - lr: 0.0100\n",
      "Epoch 11/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 3.0356 - policy_loss: 1.7834 - value_loss: 1.0001 - val_loss: 3.0828 - val_policy_loss: 1.8198 - val_value_loss: 0.9995 - lr: 0.0100\n",
      "Epoch 12/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 3.0353 - policy_loss: 1.7674 - value_loss: 0.9999 - val_loss: 3.0841 - val_policy_loss: 1.8027 - val_value_loss: 0.9993 - lr: 0.0099\n",
      "Epoch 13/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 3.0347 - policy_loss: 1.7531 - value_loss: 1.0002 - val_loss: 3.1362 - val_policy_loss: 1.8444 - val_value_loss: 0.9994 - lr: 0.0097\n",
      "Epoch 14/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 3.0126 - policy_loss: 1.7371 - value_loss: 1.0006 - val_loss: 3.0502 - val_policy_loss: 1.7907 - val_value_loss: 1.0001 - lr: 0.0094\n",
      "Epoch 15/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.9693 - policy_loss: 1.7178 - value_loss: 1.0000 - val_loss: 3.1871 - val_policy_loss: 1.9432 - val_value_loss: 0.9996 - lr: 0.0090\n",
      "Epoch 16/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.9449 - policy_loss: 1.7051 - value_loss: 0.9997 - val_loss: 3.1820 - val_policy_loss: 1.9428 - val_value_loss: 0.9996 - lr: 0.0086\n",
      "Epoch 17/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.9174 - policy_loss: 1.6916 - value_loss: 1.0000 - val_loss: 2.9793 - val_policy_loss: 1.7621 - val_value_loss: 1.0015 - lr: 0.0081\n",
      "Epoch 18/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.8812 - policy_loss: 1.6705 - value_loss: 0.9992 - val_loss: 3.0408 - val_policy_loss: 1.8377 - val_value_loss: 1.0020 - lr: 0.0076\n",
      "Epoch 19/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.8506 - policy_loss: 1.6573 - value_loss: 1.0004 - val_loss: 2.9247 - val_policy_loss: 1.7417 - val_value_loss: 0.9992 - lr: 0.0070\n",
      "Epoch 20/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.8191 - policy_loss: 1.6448 - value_loss: 0.9995 - val_loss: 2.9100 - val_policy_loss: 1.7406 - val_value_loss: 1.0000 - lr: 0.0064\n",
      "Epoch 21/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.7883 - policy_loss: 1.6284 - value_loss: 1.0000 - val_loss: 3.0954 - val_policy_loss: 1.9424 - val_value_loss: 1.0005 - lr: 0.0058\n",
      "Epoch 22/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.7689 - policy_loss: 1.6217 - value_loss: 0.9996 - val_loss: 2.8613 - val_policy_loss: 1.7183 - val_value_loss: 0.9992 - lr: 0.0052\n",
      "Epoch 23/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.7469 - policy_loss: 1.6095 - value_loss: 0.9998 - val_loss: 2.8519 - val_policy_loss: 1.7185 - val_value_loss: 0.9995 - lr: 0.0046\n",
      "Epoch 24/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.7260 - policy_loss: 1.5998 - value_loss: 0.9996 - val_loss: 2.8294 - val_policy_loss: 1.7088 - val_value_loss: 0.9995 - lr: 0.0040\n",
      "Epoch 25/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.7056 - policy_loss: 1.5903 - value_loss: 0.9996 - val_loss: 2.8323 - val_policy_loss: 1.7215 - val_value_loss: 0.9992 - lr: 0.0035\n",
      "Epoch 26/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.6860 - policy_loss: 1.5803 - value_loss: 0.9994 - val_loss: 2.8153 - val_policy_loss: 1.7134 - val_value_loss: 0.9996 - lr: 0.0030\n",
      "Epoch 27/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.6676 - policy_loss: 1.5703 - value_loss: 0.9996 - val_loss: 2.7841 - val_policy_loss: 1.6915 - val_value_loss: 0.9992 - lr: 0.0026\n",
      "Epoch 28/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.6517 - policy_loss: 1.5628 - value_loss: 0.9994 - val_loss: 2.7895 - val_policy_loss: 1.7040 - val_value_loss: 0.9992 - lr: 0.0022\n",
      "Epoch 29/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.6395 - policy_loss: 1.5568 - value_loss: 0.9995 - val_loss: 2.7781 - val_policy_loss: 1.6985 - val_value_loss: 0.9992 - lr: 0.0018\n",
      "Epoch 30/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.6275 - policy_loss: 1.5505 - value_loss: 0.9993 - val_loss: 2.7704 - val_policy_loss: 1.6958 - val_value_loss: 0.9992 - lr: 0.0015\n",
      "Epoch 31/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.6148 - policy_loss: 1.5425 - value_loss: 0.9993 - val_loss: 2.7725 - val_policy_loss: 1.7024 - val_value_loss: 0.9992 - lr: 0.0012\n",
      "Epoch 32/1000\n",
      "231/231 [==============================] - 2s 11ms/step - loss: 2.6040 - policy_loss: 1.5358 - value_loss: 0.9992 - val_loss: 2.7726 - val_policy_loss: 1.7063 - val_value_loss: 0.9992 - lr: 9.9261e-04\n",
      "Epoch 33/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5967 - policy_loss: 1.5320 - value_loss: 0.9992 - val_loss: 2.7647 - val_policy_loss: 1.7016 - val_value_loss: 0.9992 - lr: 7.9659e-04\n",
      "Epoch 34/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5909 - policy_loss: 1.5290 - value_loss: 0.9992 - val_loss: 2.7522 - val_policy_loss: 1.6916 - val_value_loss: 0.9992 - lr: 6.3292e-04\n",
      "Epoch 35/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5866 - policy_loss: 1.5271 - value_loss: 0.9992 - val_loss: 2.7566 - val_policy_loss: 1.6980 - val_value_loss: 0.9992 - lr: 4.9787e-04\n",
      "Epoch 36/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5815 - policy_loss: 1.5238 - value_loss: 0.9992 - val_loss: 2.7533 - val_policy_loss: 1.6964 - val_value_loss: 0.9992 - lr: 3.8774e-04\n",
      "Epoch 37/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5771 - policy_loss: 1.5209 - value_loss: 0.9991 - val_loss: 2.7535 - val_policy_loss: 1.6980 - val_value_loss: 0.9992 - lr: 2.9897e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5751 - policy_loss: 1.5201 - value_loss: 0.9991 - val_loss: 2.7538 - val_policy_loss: 1.6992 - val_value_loss: 0.9992 - lr: 2.2823e-04\n",
      "Epoch 39/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5735 - policy_loss: 1.5194 - value_loss: 0.9991 - val_loss: 2.7522 - val_policy_loss: 1.6985 - val_value_loss: 0.9992 - lr: 1.7249e-04\n",
      "Epoch 40/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5727 - policy_loss: 1.5193 - value_loss: 0.9991 - val_loss: 2.7516 - val_policy_loss: 1.6985 - val_value_loss: 0.9992 - lr: 1.2907e-04\n",
      "Epoch 41/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5701 - policy_loss: 1.5173 - value_loss: 0.9991 - val_loss: 2.7508 - val_policy_loss: 1.6981 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5699 - policy_loss: 1.5176 - value_loss: 0.9991 - val_loss: 2.7515 - val_policy_loss: 1.6993 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5688 - policy_loss: 1.5169 - value_loss: 0.9991 - val_loss: 2.7507 - val_policy_loss: 1.6990 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5685 - policy_loss: 1.5172 - value_loss: 0.9991 - val_loss: 2.7501 - val_policy_loss: 1.6989 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5672 - policy_loss: 1.5164 - value_loss: 0.9991 - val_loss: 2.7497 - val_policy_loss: 1.6990 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5667 - policy_loss: 1.5164 - value_loss: 0.9991 - val_loss: 2.7500 - val_policy_loss: 1.6998 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5666 - policy_loss: 1.5167 - value_loss: 0.9991 - val_loss: 2.7491 - val_policy_loss: 1.6994 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5657 - policy_loss: 1.5164 - value_loss: 0.9991 - val_loss: 2.7483 - val_policy_loss: 1.6991 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5637 - policy_loss: 1.5148 - value_loss: 0.9991 - val_loss: 2.7478 - val_policy_loss: 1.6991 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5633 - policy_loss: 1.5149 - value_loss: 0.9991 - val_loss: 2.7476 - val_policy_loss: 1.6994 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5630 - policy_loss: 1.5151 - value_loss: 0.9991 - val_loss: 2.7474 - val_policy_loss: 1.6996 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5627 - policy_loss: 1.5152 - value_loss: 0.9991 - val_loss: 2.7465 - val_policy_loss: 1.6992 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5619 - policy_loss: 1.5149 - value_loss: 0.9991 - val_loss: 2.7451 - val_policy_loss: 1.6982 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5615 - policy_loss: 1.5149 - value_loss: 0.9991 - val_loss: 2.7446 - val_policy_loss: 1.6982 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5599 - policy_loss: 1.5138 - value_loss: 0.9991 - val_loss: 2.7432 - val_policy_loss: 1.6972 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5593 - policy_loss: 1.5136 - value_loss: 0.9991 - val_loss: 2.7424 - val_policy_loss: 1.6969 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5585 - policy_loss: 1.5133 - value_loss: 0.9991 - val_loss: 2.7407 - val_policy_loss: 1.6956 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5581 - policy_loss: 1.5132 - value_loss: 0.9991 - val_loss: 2.7421 - val_policy_loss: 1.6974 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5577 - policy_loss: 1.5133 - value_loss: 0.9991 - val_loss: 2.7408 - val_policy_loss: 1.6965 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5571 - policy_loss: 1.5131 - value_loss: 0.9991 - val_loss: 2.7396 - val_policy_loss: 1.6958 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5569 - policy_loss: 1.5133 - value_loss: 0.9991 - val_loss: 2.7394 - val_policy_loss: 1.6959 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5571 - policy_loss: 1.5139 - value_loss: 0.9991 - val_loss: 2.7397 - val_policy_loss: 1.6966 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5549 - policy_loss: 1.5121 - value_loss: 0.9991 - val_loss: 2.7401 - val_policy_loss: 1.6975 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5547 - policy_loss: 1.5123 - value_loss: 0.9991 - val_loss: 2.7383 - val_policy_loss: 1.6960 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5542 - policy_loss: 1.5121 - value_loss: 0.9991 - val_loss: 2.7385 - val_policy_loss: 1.6965 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5535 - policy_loss: 1.5118 - value_loss: 0.9991 - val_loss: 2.7382 - val_policy_loss: 1.6966 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5529 - policy_loss: 1.5116 - value_loss: 0.9991 - val_loss: 2.7384 - val_policy_loss: 1.6973 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5527 - policy_loss: 1.5117 - value_loss: 0.9991 - val_loss: 2.7371 - val_policy_loss: 1.6962 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5520 - policy_loss: 1.5114 - value_loss: 0.9991 - val_loss: 2.7378 - val_policy_loss: 1.6973 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5517 - policy_loss: 1.5115 - value_loss: 0.9991 - val_loss: 2.7372 - val_policy_loss: 1.6971 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "231/231 [==============================] - 3s 12ms/step - loss: 2.5508 - policy_loss: 1.5109 - value_loss: 0.9991 - val_loss: 2.7372 - val_policy_loss: 1.6974 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5510 - policy_loss: 1.5115 - value_loss: 0.9991 - val_loss: 2.7361 - val_policy_loss: 1.6967 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5502 - policy_loss: 1.5109 - value_loss: 0.9991 - val_loss: 2.7362 - val_policy_loss: 1.6970 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5493 - policy_loss: 1.5104 - value_loss: 0.9991 - val_loss: 2.7353 - val_policy_loss: 1.6965 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5492 - policy_loss: 1.5106 - value_loss: 0.9991 - val_loss: 2.7355 - val_policy_loss: 1.6970 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5488 - policy_loss: 1.5105 - value_loss: 0.9991 - val_loss: 2.7355 - val_policy_loss: 1.6973 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5484 - policy_loss: 1.5104 - value_loss: 0.9991 - val_loss: 2.7346 - val_policy_loss: 1.6968 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5478 - policy_loss: 1.5102 - value_loss: 0.9991 - val_loss: 2.7343 - val_policy_loss: 1.6968 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5472 - policy_loss: 1.5099 - value_loss: 0.9991 - val_loss: 2.7338 - val_policy_loss: 1.6965 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5470 - policy_loss: 1.5100 - value_loss: 0.9991 - val_loss: 2.7328 - val_policy_loss: 1.6958 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5464 - policy_loss: 1.5097 - value_loss: 0.9991 - val_loss: 2.7330 - val_policy_loss: 1.6963 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5456 - policy_loss: 1.5092 - value_loss: 0.9991 - val_loss: 2.7316 - val_policy_loss: 1.6953 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5450 - policy_loss: 1.5088 - value_loss: 0.9991 - val_loss: 2.7313 - val_policy_loss: 1.6953 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5456 - policy_loss: 1.5098 - value_loss: 0.9991 - val_loss: 2.7326 - val_policy_loss: 1.6968 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5450 - policy_loss: 1.5094 - value_loss: 0.9991 - val_loss: 2.7295 - val_policy_loss: 1.6940 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5441 - policy_loss: 1.5088 - value_loss: 0.9991 - val_loss: 2.7304 - val_policy_loss: 1.6952 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5439 - policy_loss: 1.5089 - value_loss: 0.9991 - val_loss: 2.7305 - val_policy_loss: 1.6956 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5436 - policy_loss: 1.5088 - value_loss: 0.9991 - val_loss: 2.7317 - val_policy_loss: 1.6970 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5433 - policy_loss: 1.5088 - value_loss: 0.9991 - val_loss: 2.7314 - val_policy_loss: 1.6970 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5427 - policy_loss: 1.5084 - value_loss: 0.9991 - val_loss: 2.7299 - val_policy_loss: 1.6957 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5424 - policy_loss: 1.5084 - value_loss: 0.9991 - val_loss: 2.7296 - val_policy_loss: 1.6957 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5423 - policy_loss: 1.5087 - value_loss: 0.9991 - val_loss: 2.7294 - val_policy_loss: 1.6957 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5415 - policy_loss: 1.5080 - value_loss: 0.9991 - val_loss: 2.7271 - val_policy_loss: 1.6937 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5419 - policy_loss: 1.5087 - value_loss: 0.9991 - val_loss: 2.7283 - val_policy_loss: 1.6951 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5409 - policy_loss: 1.5080 - value_loss: 0.9991 - val_loss: 2.7293 - val_policy_loss: 1.6964 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5398 - policy_loss: 1.5071 - value_loss: 0.9991 - val_loss: 2.7280 - val_policy_loss: 1.6954 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5401 - policy_loss: 1.5077 - value_loss: 0.9991 - val_loss: 2.7277 - val_policy_loss: 1.6952 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5403 - policy_loss: 1.5080 - value_loss: 0.9991 - val_loss: 2.7295 - val_policy_loss: 1.6973 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5395 - policy_loss: 1.5075 - value_loss: 0.9991 - val_loss: 2.7285 - val_policy_loss: 1.6966 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5402 - policy_loss: 1.5085 - value_loss: 0.9991 - val_loss: 2.7275 - val_policy_loss: 1.6958 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5400 - policy_loss: 1.5085 - value_loss: 0.9991 - val_loss: 2.7277 - val_policy_loss: 1.6962 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5386 - policy_loss: 1.5073 - value_loss: 0.9991 - val_loss: 2.7270 - val_policy_loss: 1.6957 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5382 - policy_loss: 1.5071 - value_loss: 0.9991 - val_loss: 2.7266 - val_policy_loss: 1.6955 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5390 - policy_loss: 1.5081 - value_loss: 0.9991 - val_loss: 2.7270 - val_policy_loss: 1.6962 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5382 - policy_loss: 1.5075 - value_loss: 0.9991 - val_loss: 2.7270 - val_policy_loss: 1.6963 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5380 - policy_loss: 1.5075 - value_loss: 0.9991 - val_loss: 2.7289 - val_policy_loss: 1.6984 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5375 - policy_loss: 1.5072 - value_loss: 0.9991 - val_loss: 2.7274 - val_policy_loss: 1.6972 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5372 - policy_loss: 1.5071 - value_loss: 0.9991 - val_loss: 2.7272 - val_policy_loss: 1.6971 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5370 - policy_loss: 1.5071 - value_loss: 0.9991 - val_loss: 2.7279 - val_policy_loss: 1.6981 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5365 - policy_loss: 1.5068 - value_loss: 0.9991 - val_loss: 2.7275 - val_policy_loss: 1.6979 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5359 - policy_loss: 1.5064 - value_loss: 0.9991 - val_loss: 2.7268 - val_policy_loss: 1.6973 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5363 - policy_loss: 1.5070 - value_loss: 0.9991 - val_loss: 2.7252 - val_policy_loss: 1.6960 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5357 - policy_loss: 1.5066 - value_loss: 0.9991 - val_loss: 2.7278 - val_policy_loss: 1.6988 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 114/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5356 - policy_loss: 1.5067 - value_loss: 0.9991 - val_loss: 2.7267 - val_policy_loss: 1.6979 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5345 - policy_loss: 1.5058 - value_loss: 0.9991 - val_loss: 2.7240 - val_policy_loss: 1.6953 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5354 - policy_loss: 1.5069 - value_loss: 0.9991 - val_loss: 2.7234 - val_policy_loss: 1.6949 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5348 - policy_loss: 1.5065 - value_loss: 0.9991 - val_loss: 2.7249 - val_policy_loss: 1.6966 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5346 - policy_loss: 1.5065 - value_loss: 0.9991 - val_loss: 2.7246 - val_policy_loss: 1.6965 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5347 - policy_loss: 1.5068 - value_loss: 0.9991 - val_loss: 2.7250 - val_policy_loss: 1.6970 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5337 - policy_loss: 1.5059 - value_loss: 0.9991 - val_loss: 2.7246 - val_policy_loss: 1.6968 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5340 - policy_loss: 1.5063 - value_loss: 0.9991 - val_loss: 2.7240 - val_policy_loss: 1.6964 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5340 - policy_loss: 1.5066 - value_loss: 0.9991 - val_loss: 2.7249 - val_policy_loss: 1.6974 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5334 - policy_loss: 1.5061 - value_loss: 0.9991 - val_loss: 2.7257 - val_policy_loss: 1.6985 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5333 - policy_loss: 1.5062 - value_loss: 0.9991 - val_loss: 2.7254 - val_policy_loss: 1.6983 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5326 - policy_loss: 1.5056 - value_loss: 0.9991 - val_loss: 2.7231 - val_policy_loss: 1.6962 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5327 - policy_loss: 1.5059 - value_loss: 0.9991 - val_loss: 2.7239 - val_policy_loss: 1.6971 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5317 - policy_loss: 1.5050 - value_loss: 0.9991 - val_loss: 2.7240 - val_policy_loss: 1.6974 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5318 - policy_loss: 1.5054 - value_loss: 0.9991 - val_loss: 2.7231 - val_policy_loss: 1.6967 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5320 - policy_loss: 1.5057 - value_loss: 0.9991 - val_loss: 2.7233 - val_policy_loss: 1.6970 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5309 - policy_loss: 1.5047 - value_loss: 0.9991 - val_loss: 2.7216 - val_policy_loss: 1.6955 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5314 - policy_loss: 1.5054 - value_loss: 0.9991 - val_loss: 2.7242 - val_policy_loss: 1.6983 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5309 - policy_loss: 1.5051 - value_loss: 0.9991 - val_loss: 2.7220 - val_policy_loss: 1.6962 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5307 - policy_loss: 1.5051 - value_loss: 0.9991 - val_loss: 2.7234 - val_policy_loss: 1.6977 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5303 - policy_loss: 1.5049 - value_loss: 0.9991 - val_loss: 2.7229 - val_policy_loss: 1.6974 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5306 - policy_loss: 1.5052 - value_loss: 0.9991 - val_loss: 2.7198 - val_policy_loss: 1.6945 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5305 - policy_loss: 1.5053 - value_loss: 0.9991 - val_loss: 2.7220 - val_policy_loss: 1.6968 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "231/231 [==============================] - 2s 10ms/step - loss: 2.5301 - policy_loss: 1.5051 - value_loss: 0.9991 - val_loss: 2.7209 - val_policy_loss: 1.6959 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5295 - policy_loss: 1.5046 - value_loss: 0.9991 - val_loss: 2.7219 - val_policy_loss: 1.6970 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5293 - policy_loss: 1.5045 - value_loss: 0.9991 - val_loss: 2.7216 - val_policy_loss: 1.6968 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5298 - policy_loss: 1.5052 - value_loss: 0.9991 - val_loss: 2.7224 - val_policy_loss: 1.6978 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5292 - policy_loss: 1.5048 - value_loss: 0.9991 - val_loss: 2.7204 - val_policy_loss: 1.6959 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5288 - policy_loss: 1.5045 - value_loss: 0.9991 - val_loss: 2.7218 - val_policy_loss: 1.6975 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5289 - policy_loss: 1.5047 - value_loss: 0.9991 - val_loss: 2.7225 - val_policy_loss: 1.6984 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5285 - policy_loss: 1.5045 - value_loss: 0.9991 - val_loss: 2.7201 - val_policy_loss: 1.6961 - val_value_loss: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "231/231 [==============================] - 2s 9ms/step - loss: 2.5285 - policy_loss: 1.5046 - value_loss: 0.9991 - val_loss: 2.7204 - val_policy_loss: 1.6965 - val_value_loss: 0.9992 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "fit_history = trainer.train(flatten_dataset, n_epochs=1000, batch_size=30, learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('saved_model/tmp_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the self-playing dataset (2nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loaded_model = tf.keras.models.load_model(\"saved_model/alpha_zero_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# speed test on 4 games\n",
    "start_time = time.time()\n",
    "trainer = Trainer(game = FourInARow, mcts = MCTS, model=loaded_model)\n",
    "dataset = trainer.create_dataset(number_of_games=4, temperature=1)\n",
    "print(\"Running time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROUNDS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_fn(job_n, cache, n):\n",
    "    \n",
    "    from libs.Trainer import Trainer\n",
    "    from libs.FourInARow import FourInARow\n",
    "    from libs.model import CachedModel\n",
    "    from libs.MCTS import MCTS\n",
    "    import tensorflow as tf\n",
    "    N_GAMES_PER_JOB = 25\n",
    "    STARTING_TEMPERATURE = 10.0\n",
    "    \n",
    "    model = tf.keras.models.load_model(\"saved_model/tmp_model\")\n",
    "    trainer = Trainer(game = FourInARow, mcts = MCTS, model=CachedModel(model=model))\n",
    "    \n",
    "    game_batch = trainer.create_dataset(number_of_games=N_GAMES_PER_JOB, temperature=STARTING_TEMPERATURE/n)\n",
    "    \n",
    "    return game_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_cache type: <class 'multiprocess.managers.DictProxy'>\n",
      "Number of args: 16\n",
      "[(0, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (1, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (2, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (3, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (4, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (5, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (6, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (7, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (8, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (9, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (10, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (11, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (12, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (13, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (14, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1), (15, <DictProxy object, typeid 'dict' at 0x228764f8670>, 1)]\n",
      "Running time 1-th round: 2783.552307367325 seconds\n",
      "Dataset size: 13450\n",
      "Epoch 1/50\n",
      "243/243 [==============================] - 4s 12ms/step - loss: 4.4088 - policy_loss: 2.2786 - value_loss: 1.9293 - val_loss: 3.9987 - val_policy_loss: 1.9444 - val_value_loss: 1.9271 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 3.9508 - policy_loss: 1.9414 - value_loss: 1.9297 - val_loss: 3.9182 - val_policy_loss: 1.9453 - val_value_loss: 1.9271 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 3.9008 - policy_loss: 1.9415 - value_loss: 1.9298 - val_loss: 3.8887 - val_policy_loss: 1.9436 - val_value_loss: 1.9271 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 3.3705 - policy_loss: 1.9415 - value_loss: 1.3867 - val_loss: 2.9667 - val_policy_loss: 1.9444 - val_value_loss: 1.0042 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9522 - policy_loss: 1.9415 - value_loss: 1.0003 - val_loss: 2.9493 - val_policy_loss: 1.9442 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9452 - policy_loss: 1.9416 - value_loss: 0.9992 - val_loss: 2.9489 - val_policy_loss: 1.9460 - val_value_loss: 0.9995 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9440 - policy_loss: 1.9414 - value_loss: 1.0000 - val_loss: 2.9447 - val_policy_loss: 1.9437 - val_value_loss: 0.9988 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9431 - policy_loss: 1.9415 - value_loss: 0.9998 - val_loss: 2.9448 - val_policy_loss: 1.9442 - val_value_loss: 0.9991 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9426 - policy_loss: 1.9415 - value_loss: 0.9998 - val_loss: 2.9459 - val_policy_loss: 1.9459 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9416 - policy_loss: 1.9415 - value_loss: 0.9992 - val_loss: 2.9447 - val_policy_loss: 1.9441 - val_value_loss: 0.9998 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9418 - policy_loss: 1.9415 - value_loss: 0.9996 - val_loss: 2.9437 - val_policy_loss: 1.9434 - val_value_loss: 0.9997 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9413 - policy_loss: 1.9415 - value_loss: 0.9993 - val_loss: 2.9437 - val_policy_loss: 1.9445 - val_value_loss: 0.9987 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9408 - policy_loss: 1.9415 - value_loss: 0.9989 - val_loss: 2.9453 - val_policy_loss: 1.9445 - val_value_loss: 1.0005 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9415 - policy_loss: 1.9417 - value_loss: 0.9995 - val_loss: 2.9459 - val_policy_loss: 1.9452 - val_value_loss: 1.0005 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9411 - policy_loss: 1.9417 - value_loss: 0.9992 - val_loss: 2.9431 - val_policy_loss: 1.9434 - val_value_loss: 0.9995 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9413 - policy_loss: 1.9416 - value_loss: 0.9995 - val_loss: 2.9434 - val_policy_loss: 1.9438 - val_value_loss: 0.9994 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9405 - policy_loss: 1.9415 - value_loss: 0.9989 - val_loss: 2.9431 - val_policy_loss: 1.9442 - val_value_loss: 0.9988 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9409 - policy_loss: 1.9413 - value_loss: 0.9995 - val_loss: 2.9452 - val_policy_loss: 1.9459 - val_value_loss: 0.9992 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9407 - policy_loss: 1.9414 - value_loss: 0.9993 - val_loss: 2.9437 - val_policy_loss: 1.9449 - val_value_loss: 0.9987 - lr: 0.0070\n",
      "Epoch 20/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9406 - policy_loss: 1.9414 - value_loss: 0.9992 - val_loss: 2.9431 - val_policy_loss: 1.9444 - val_value_loss: 0.9987 - lr: 0.0064\n",
      "Epoch 21/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9405 - policy_loss: 1.9414 - value_loss: 0.9991 - val_loss: 2.9441 - val_policy_loss: 1.9452 - val_value_loss: 0.9988 - lr: 0.0058\n",
      "Epoch 22/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9407 - policy_loss: 1.9414 - value_loss: 0.9993 - val_loss: 2.9435 - val_policy_loss: 1.9447 - val_value_loss: 0.9987 - lr: 0.0052\n",
      "Epoch 23/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9406 - policy_loss: 1.9414 - value_loss: 0.9992 - val_loss: 2.9436 - val_policy_loss: 1.9448 - val_value_loss: 0.9987 - lr: 0.0046\n",
      "Epoch 24/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9403 - policy_loss: 1.9413 - value_loss: 0.9989 - val_loss: 2.9438 - val_policy_loss: 1.9447 - val_value_loss: 0.9991 - lr: 0.0040\n",
      "Epoch 25/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9403 - policy_loss: 1.9413 - value_loss: 0.9990 - val_loss: 2.9431 - val_policy_loss: 1.9444 - val_value_loss: 0.9987 - lr: 0.0035\n",
      "Epoch 26/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9403 - policy_loss: 1.9413 - value_loss: 0.9989 - val_loss: 2.9436 - val_policy_loss: 1.9448 - val_value_loss: 0.9988 - lr: 0.0030\n",
      "Epoch 27/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9403 - policy_loss: 1.9413 - value_loss: 0.9990 - val_loss: 2.9433 - val_policy_loss: 1.9446 - val_value_loss: 0.9987 - lr: 0.0026\n",
      "Epoch 28/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9402 - policy_loss: 1.9413 - value_loss: 0.9990 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 0.0022\n",
      "Epoch 29/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9401 - policy_loss: 1.9412 - value_loss: 0.9989 - val_loss: 2.9432 - val_policy_loss: 1.9443 - val_value_loss: 0.9988 - lr: 0.0018\n",
      "Epoch 30/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9401 - policy_loss: 1.9412 - value_loss: 0.9989 - val_loss: 2.9434 - val_policy_loss: 1.9447 - val_value_loss: 0.9987 - lr: 0.0015\n",
      "Epoch 31/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9401 - policy_loss: 1.9412 - value_loss: 0.9989 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9401 - policy_loss: 1.9412 - value_loss: 0.9989 - val_loss: 2.9429 - val_policy_loss: 1.9442 - val_value_loss: 0.9987 - lr: 9.9261e-04\n",
      "Epoch 33/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9400 - policy_loss: 1.9412 - value_loss: 0.9989 - val_loss: 2.9429 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 7.9659e-04\n",
      "Epoch 34/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9400 - policy_loss: 1.9412 - value_loss: 0.9989 - val_loss: 2.9431 - val_policy_loss: 1.9444 - val_value_loss: 0.9987 - lr: 6.3292e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9400 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9431 - val_policy_loss: 1.9444 - val_value_loss: 0.9987 - lr: 4.9787e-04\n",
      "Epoch 36/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9400 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 3.8774e-04\n",
      "Epoch 37/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9400 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 2.9897e-04\n",
      "Epoch 38/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9399 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 2.2823e-04\n",
      "Epoch 39/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9399 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 1.7249e-04\n",
      "Epoch 40/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9399 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 1.2907e-04\n",
      "Epoch 41/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9399 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "243/243 [==============================] - 3s 11ms/step - loss: 2.9399 - policy_loss: 1.9411 - value_loss: 0.9988 - val_loss: 2.9430 - val_policy_loss: 1.9443 - val_value_loss: 0.9987 - lr: 1.0000e-04\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_cache type: <class 'multiprocess.managers.DictProxy'>\n",
      "Number of args: 16\n",
      "[(0, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (1, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (2, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (3, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (4, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (5, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (6, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (7, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (8, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (9, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (10, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (11, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (12, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (13, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (14, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2), (15, <DictProxy object, typeid 'dict' at 0x22870ec4490>, 2)]\n",
      "Running time 2-th round: 3462.2093093395233 seconds\n",
      "Dataset size: 20872\n",
      "Epoch 1/50\n",
      "376/376 [==============================] - 6s 11ms/step - loss: 2.9377 - policy_loss: 1.9385 - value_loss: 0.9992 - val_loss: 2.9296 - val_policy_loss: 1.9303 - val_value_loss: 0.9993 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9381 - policy_loss: 1.9385 - value_loss: 0.9996 - val_loss: 2.9309 - val_policy_loss: 1.9301 - val_value_loss: 1.0008 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9379 - policy_loss: 1.9384 - value_loss: 0.9995 - val_loss: 2.9305 - val_policy_loss: 1.9314 - val_value_loss: 0.9991 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9380 - policy_loss: 1.9385 - value_loss: 0.9995 - val_loss: 2.9305 - val_policy_loss: 1.9308 - val_value_loss: 0.9998 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9376 - policy_loss: 1.9385 - value_loss: 0.9991 - val_loss: 2.9315 - val_policy_loss: 1.9299 - val_value_loss: 1.0016 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9379 - policy_loss: 1.9383 - value_loss: 0.9995 - val_loss: 2.9316 - val_policy_loss: 1.9316 - val_value_loss: 1.0000 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9379 - policy_loss: 1.9384 - value_loss: 0.9995 - val_loss: 2.9295 - val_policy_loss: 1.9295 - val_value_loss: 1.0000 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9382 - policy_loss: 1.9384 - value_loss: 0.9998 - val_loss: 2.9318 - val_policy_loss: 1.9312 - val_value_loss: 1.0006 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9380 - policy_loss: 1.9385 - value_loss: 0.9995 - val_loss: 2.9286 - val_policy_loss: 1.9295 - val_value_loss: 0.9992 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9381 - policy_loss: 1.9385 - value_loss: 0.9996 - val_loss: 2.9315 - val_policy_loss: 1.9306 - val_value_loss: 1.0009 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9379 - policy_loss: 1.9385 - value_loss: 0.9995 - val_loss: 2.9292 - val_policy_loss: 1.9301 - val_value_loss: 0.9992 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9381 - policy_loss: 1.9384 - value_loss: 0.9997 - val_loss: 2.9310 - val_policy_loss: 1.9318 - val_value_loss: 0.9992 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9380 - policy_loss: 1.9384 - value_loss: 0.9996 - val_loss: 2.9325 - val_policy_loss: 1.9305 - val_value_loss: 1.0020 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9387 - policy_loss: 1.9385 - value_loss: 1.0002 - val_loss: 2.9286 - val_policy_loss: 1.9290 - val_value_loss: 0.9997 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9378 - policy_loss: 1.9384 - value_loss: 0.9994 - val_loss: 2.9299 - val_policy_loss: 1.9301 - val_value_loss: 0.9997 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9380 - policy_loss: 1.9384 - value_loss: 0.9996 - val_loss: 2.9307 - val_policy_loss: 1.9307 - val_value_loss: 1.0000 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9380 - policy_loss: 1.9384 - value_loss: 0.9996 - val_loss: 2.9293 - val_policy_loss: 1.9302 - val_value_loss: 0.9991 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9379 - policy_loss: 1.9383 - value_loss: 0.9995 - val_loss: 2.9294 - val_policy_loss: 1.9297 - val_value_loss: 0.9997 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "376/376 [==============================] - 4s 11ms/step - loss: 2.9375 - policy_loss: 1.9383 - value_loss: 0.9992 - val_loss: 2.9299 - val_policy_loss: 1.9306 - val_value_loss: 0.9994 - lr: 0.0070\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_cache type: <class 'multiprocess.managers.DictProxy'>\n",
      "Number of args: 16\n",
      "[(0, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (1, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (2, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (3, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (4, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (5, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (6, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (7, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (8, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (9, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (10, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (11, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (12, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (13, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (14, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3), (15, <DictProxy object, typeid 'dict' at 0x2280c43f1c0>, 3)]\n",
      "Running time 3-th round: 3341.4112412929535 seconds\n",
      "Dataset size: 28125\n",
      "Epoch 1/50\n",
      "507/507 [==============================] - 7s 11ms/step - loss: 2.9350 - policy_loss: 1.9353 - value_loss: 0.9997 - val_loss: 2.9270 - val_policy_loss: 1.9270 - val_value_loss: 1.0000 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9349 - policy_loss: 1.9354 - value_loss: 0.9995 - val_loss: 2.9260 - val_policy_loss: 1.9270 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9352 - policy_loss: 1.9354 - value_loss: 0.9998 - val_loss: 2.9263 - val_policy_loss: 1.9270 - val_value_loss: 0.9993 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9351 - policy_loss: 1.9353 - value_loss: 0.9997 - val_loss: 2.9273 - val_policy_loss: 1.9280 - val_value_loss: 0.9993 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9353 - policy_loss: 1.9354 - value_loss: 0.9999 - val_loss: 2.9278 - val_policy_loss: 1.9280 - val_value_loss: 0.9998 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9352 - policy_loss: 1.9354 - value_loss: 0.9998 - val_loss: 2.9264 - val_policy_loss: 1.9274 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9353 - policy_loss: 1.9354 - value_loss: 0.9999 - val_loss: 2.9267 - val_policy_loss: 1.9276 - val_value_loss: 0.9991 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9350 - policy_loss: 1.9354 - value_loss: 0.9995 - val_loss: 2.9276 - val_policy_loss: 1.9273 - val_value_loss: 1.0003 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 2.9351 - policy_loss: 1.9354 - value_loss: 0.9997 - val_loss: 2.9266 - val_policy_loss: 1.9270 - val_value_loss: 0.9996 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9350 - policy_loss: 1.9354 - value_loss: 0.9996 - val_loss: 2.9257 - val_policy_loss: 1.9267 - val_value_loss: 0.9990 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9349 - policy_loss: 1.9354 - value_loss: 0.9995 - val_loss: 2.9255 - val_policy_loss: 1.9265 - val_value_loss: 0.9990 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9350 - policy_loss: 1.9355 - value_loss: 0.9996 - val_loss: 2.9256 - val_policy_loss: 1.9263 - val_value_loss: 0.9993 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9350 - policy_loss: 1.9354 - value_loss: 0.9996 - val_loss: 2.9262 - val_policy_loss: 1.9273 - val_value_loss: 0.9989 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 2.9348 - policy_loss: 1.9354 - value_loss: 0.9994 - val_loss: 2.9281 - val_policy_loss: 1.9268 - val_value_loss: 1.0014 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9349 - policy_loss: 1.9354 - value_loss: 0.9995 - val_loss: 2.9262 - val_policy_loss: 1.9272 - val_value_loss: 0.9989 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "507/507 [==============================] - 5s 11ms/step - loss: 2.9351 - policy_loss: 1.9354 - value_loss: 0.9998 - val_loss: 2.9270 - val_policy_loss: 1.9281 - val_value_loss: 0.9989 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9347 - policy_loss: 1.9353 - value_loss: 0.9994 - val_loss: 2.9281 - val_policy_loss: 1.9270 - val_value_loss: 1.0011 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9347 - policy_loss: 1.9353 - value_loss: 0.9994 - val_loss: 2.9273 - val_policy_loss: 1.9284 - val_value_loss: 0.9989 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9349 - policy_loss: 1.9353 - value_loss: 0.9996 - val_loss: 2.9258 - val_policy_loss: 1.9269 - val_value_loss: 0.9989 - lr: 0.0070\n",
      "Epoch 20/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9344 - policy_loss: 1.9353 - value_loss: 0.9992 - val_loss: 2.9263 - val_policy_loss: 1.9273 - val_value_loss: 0.9991 - lr: 0.0064\n",
      "Epoch 21/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9346 - policy_loss: 1.9352 - value_loss: 0.9994 - val_loss: 2.9247 - val_policy_loss: 1.9258 - val_value_loss: 0.9989 - lr: 0.0058\n",
      "Epoch 22/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9346 - policy_loss: 1.9352 - value_loss: 0.9993 - val_loss: 2.9261 - val_policy_loss: 1.9269 - val_value_loss: 0.9991 - lr: 0.0052\n",
      "Epoch 23/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9343 - policy_loss: 1.9352 - value_loss: 0.9991 - val_loss: 2.9266 - val_policy_loss: 1.9269 - val_value_loss: 0.9996 - lr: 0.0046\n",
      "Epoch 24/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9345 - policy_loss: 1.9351 - value_loss: 0.9993 - val_loss: 2.9263 - val_policy_loss: 1.9268 - val_value_loss: 0.9994 - lr: 0.0040\n",
      "Epoch 25/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9344 - policy_loss: 1.9351 - value_loss: 0.9993 - val_loss: 2.9260 - val_policy_loss: 1.9270 - val_value_loss: 0.9989 - lr: 0.0035\n",
      "Epoch 26/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9343 - policy_loss: 1.9351 - value_loss: 0.9992 - val_loss: 2.9258 - val_policy_loss: 1.9268 - val_value_loss: 0.9990 - lr: 0.0030\n",
      "Epoch 27/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9341 - policy_loss: 1.9351 - value_loss: 0.9990 - val_loss: 2.9262 - val_policy_loss: 1.9268 - val_value_loss: 0.9994 - lr: 0.0026\n",
      "Epoch 28/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9341 - policy_loss: 1.9351 - value_loss: 0.9990 - val_loss: 2.9263 - val_policy_loss: 1.9275 - val_value_loss: 0.9989 - lr: 0.0022\n",
      "Epoch 29/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9341 - policy_loss: 1.9351 - value_loss: 0.9991 - val_loss: 2.9256 - val_policy_loss: 1.9267 - val_value_loss: 0.9989 - lr: 0.0018\n",
      "Epoch 30/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9342 - policy_loss: 1.9351 - value_loss: 0.9991 - val_loss: 2.9257 - val_policy_loss: 1.9268 - val_value_loss: 0.9990 - lr: 0.0015\n",
      "Epoch 31/50\n",
      "507/507 [==============================] - 6s 11ms/step - loss: 2.9341 - policy_loss: 1.9351 - value_loss: 0.9990 - val_loss: 2.9257 - val_policy_loss: 1.9268 - val_value_loss: 0.9989 - lr: 0.0012\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_cache type: <class 'multiprocess.managers.DictProxy'>\n",
      "Number of args: 16\n",
      "[(0, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (1, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (2, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (3, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (4, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (5, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (6, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (7, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (8, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (9, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (10, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (11, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (12, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (13, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (14, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4), (15, <DictProxy object, typeid 'dict' at 0x22870e31eb0>, 4)]\n",
      "Running time 4-th round: 3251.381306409836 seconds\n",
      "Dataset size: 34868\n",
      "Epoch 1/50\n",
      "628/628 [==============================] - 9s 11ms/step - loss: 2.9327 - policy_loss: 1.9333 - value_loss: 0.9994 - val_loss: 2.9196 - val_policy_loss: 1.9176 - val_value_loss: 1.0019 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9328 - policy_loss: 1.9333 - value_loss: 0.9995 - val_loss: 2.9181 - val_policy_loss: 1.9192 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9330 - policy_loss: 1.9333 - value_loss: 0.9996 - val_loss: 2.9168 - val_policy_loss: 1.9174 - val_value_loss: 0.9994 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9329 - policy_loss: 1.9334 - value_loss: 0.9996 - val_loss: 2.9171 - val_policy_loss: 1.9174 - val_value_loss: 0.9997 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9329 - policy_loss: 1.9333 - value_loss: 0.9996 - val_loss: 2.9159 - val_policy_loss: 1.9170 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9331 - policy_loss: 1.9334 - value_loss: 0.9997 - val_loss: 2.9156 - val_policy_loss: 1.9167 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9326 - policy_loss: 1.9333 - value_loss: 0.9993 - val_loss: 2.9171 - val_policy_loss: 1.9183 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9325 - policy_loss: 1.9333 - value_loss: 0.9992 - val_loss: 2.9184 - val_policy_loss: 1.9188 - val_value_loss: 0.9996 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9332 - policy_loss: 1.9333 - value_loss: 0.9999 - val_loss: 2.9182 - val_policy_loss: 1.9192 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9330 - policy_loss: 1.9334 - value_loss: 0.9996 - val_loss: 2.9176 - val_policy_loss: 1.9184 - val_value_loss: 0.9992 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9331 - policy_loss: 1.9333 - value_loss: 0.9998 - val_loss: 2.9159 - val_policy_loss: 1.9171 - val_value_loss: 0.9988 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9331 - policy_loss: 1.9334 - value_loss: 0.9997 - val_loss: 2.9172 - val_policy_loss: 1.9182 - val_value_loss: 0.9990 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9327 - policy_loss: 1.9334 - value_loss: 0.9993 - val_loss: 2.9206 - val_policy_loss: 1.9200 - val_value_loss: 1.0007 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9330 - policy_loss: 1.9333 - value_loss: 0.9997 - val_loss: 2.9188 - val_policy_loss: 1.9197 - val_value_loss: 0.9992 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9330 - policy_loss: 1.9333 - value_loss: 0.9997 - val_loss: 2.9154 - val_policy_loss: 1.9166 - val_value_loss: 0.9988 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9329 - policy_loss: 1.9333 - value_loss: 0.9996 - val_loss: 2.9168 - val_policy_loss: 1.9177 - val_value_loss: 0.9990 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9330 - policy_loss: 1.9333 - value_loss: 0.9997 - val_loss: 2.9165 - val_policy_loss: 1.9176 - val_value_loss: 0.9988 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9329 - policy_loss: 1.9332 - value_loss: 0.9997 - val_loss: 2.9195 - val_policy_loss: 1.9174 - val_value_loss: 1.0021 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9329 - policy_loss: 1.9332 - value_loss: 0.9996 - val_loss: 2.9191 - val_policy_loss: 1.9195 - val_value_loss: 0.9996 - lr: 0.0070\n",
      "Epoch 20/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9325 - policy_loss: 1.9332 - value_loss: 0.9993 - val_loss: 2.9171 - val_policy_loss: 1.9176 - val_value_loss: 0.9994 - lr: 0.0064\n",
      "Epoch 21/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9326 - policy_loss: 1.9332 - value_loss: 0.9993 - val_loss: 2.9158 - val_policy_loss: 1.9170 - val_value_loss: 0.9988 - lr: 0.0058\n",
      "Epoch 22/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9322 - policy_loss: 1.9332 - value_loss: 0.9990 - val_loss: 2.9176 - val_policy_loss: 1.9180 - val_value_loss: 0.9996 - lr: 0.0052\n",
      "Epoch 23/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9324 - policy_loss: 1.9331 - value_loss: 0.9992 - val_loss: 2.9167 - val_policy_loss: 1.9178 - val_value_loss: 0.9990 - lr: 0.0046\n",
      "Epoch 24/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9322 - policy_loss: 1.9331 - value_loss: 0.9991 - val_loss: 2.9164 - val_policy_loss: 1.9173 - val_value_loss: 0.9992 - lr: 0.0040\n",
      "Epoch 25/50\n",
      "628/628 [==============================] - 7s 11ms/step - loss: 2.9322 - policy_loss: 1.9331 - value_loss: 0.9992 - val_loss: 2.9173 - val_policy_loss: 1.9182 - val_value_loss: 0.9991 - lr: 0.0035\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_cache type: <class 'multiprocess.managers.DictProxy'>\n",
      "Number of args: 16\n",
      "[(0, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (1, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (2, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (3, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (4, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (5, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (6, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (7, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (8, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (9, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (10, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (11, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (12, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (13, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (14, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5), (15, <DictProxy object, typeid 'dict' at 0x22866c57cd0>, 5)]\n",
      "Running time 5-th round: 3481.5161719322205 seconds\n",
      "Dataset size: 41806\n",
      "Epoch 1/50\n",
      "753/753 [==============================] - 9s 11ms/step - loss: 2.9308 - policy_loss: 1.9308 - value_loss: 1.0000 - val_loss: 2.9204 - val_policy_loss: 1.9213 - val_value_loss: 0.9991 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9303 - policy_loss: 1.9309 - value_loss: 0.9994 - val_loss: 2.9192 - val_policy_loss: 1.9195 - val_value_loss: 0.9996 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9306 - policy_loss: 1.9308 - value_loss: 0.9998 - val_loss: 2.9226 - val_policy_loss: 1.9210 - val_value_loss: 1.0016 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "753/753 [==============================] - 8s 10ms/step - loss: 2.9307 - policy_loss: 1.9308 - value_loss: 0.9999 - val_loss: 2.9205 - val_policy_loss: 1.9215 - val_value_loss: 0.9990 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "753/753 [==============================] - 8s 10ms/step - loss: 2.9303 - policy_loss: 1.9309 - value_loss: 0.9995 - val_loss: 2.9204 - val_policy_loss: 1.9214 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "753/753 [==============================] - 8s 10ms/step - loss: 2.9305 - policy_loss: 1.9309 - value_loss: 0.9996 - val_loss: 2.9205 - val_policy_loss: 1.9214 - val_value_loss: 0.9991 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "753/753 [==============================] - 8s 10ms/step - loss: 2.9303 - policy_loss: 1.9309 - value_loss: 0.9994 - val_loss: 2.9200 - val_policy_loss: 1.9210 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9307 - policy_loss: 1.9309 - value_loss: 0.9998 - val_loss: 2.9205 - val_policy_loss: 1.9209 - val_value_loss: 0.9996 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9303 - policy_loss: 1.9308 - value_loss: 0.9995 - val_loss: 2.9185 - val_policy_loss: 1.9196 - val_value_loss: 0.9989 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9304 - policy_loss: 1.9309 - value_loss: 0.9995 - val_loss: 2.9198 - val_policy_loss: 1.9203 - val_value_loss: 0.9995 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9302 - policy_loss: 1.9309 - value_loss: 0.9994 - val_loss: 2.9223 - val_policy_loss: 1.9214 - val_value_loss: 1.0010 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9304 - policy_loss: 1.9308 - value_loss: 0.9996 - val_loss: 2.9197 - val_policy_loss: 1.9208 - val_value_loss: 0.9989 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9304 - policy_loss: 1.9308 - value_loss: 0.9995 - val_loss: 2.9197 - val_policy_loss: 1.9207 - val_value_loss: 0.9990 - lr: 0.0097\n",
      "Epoch 14/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9306 - policy_loss: 1.9309 - value_loss: 0.9997 - val_loss: 2.9203 - val_policy_loss: 1.9207 - val_value_loss: 0.9996 - lr: 0.0094\n",
      "Epoch 15/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9305 - policy_loss: 1.9308 - value_loss: 0.9997 - val_loss: 2.9222 - val_policy_loss: 1.9208 - val_value_loss: 1.0014 - lr: 0.0090\n",
      "Epoch 16/50\n",
      "753/753 [==============================] - 8s 11ms/step - loss: 2.9302 - policy_loss: 1.9308 - value_loss: 0.9993 - val_loss: 2.9233 - val_policy_loss: 1.9210 - val_value_loss: 1.0024 - lr: 0.0086\n",
      "Epoch 17/50\n",
      "753/753 [==============================] - 8s 10ms/step - loss: 2.9303 - policy_loss: 1.9308 - value_loss: 0.9995 - val_loss: 2.9200 - val_policy_loss: 1.9212 - val_value_loss: 0.9988 - lr: 0.0081\n",
      "Epoch 18/50\n",
      "753/753 [==============================] - 8s 10ms/step - loss: 2.9307 - policy_loss: 1.9308 - value_loss: 0.9998 - val_loss: 2.9198 - val_policy_loss: 1.9207 - val_value_loss: 0.9992 - lr: 0.0076\n",
      "Epoch 19/50\n",
      "753/753 [==============================] - 8s 10ms/step - loss: 2.9301 - policy_loss: 1.9307 - value_loss: 0.9994 - val_loss: 2.9214 - val_policy_loss: 1.9219 - val_value_loss: 0.9995 - lr: 0.0070\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_cache type: <class 'multiprocess.managers.DictProxy'>\n",
      "Number of args: 16\n",
      "[(0, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (1, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (2, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (3, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (4, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (5, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (6, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (7, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (8, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (9, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (10, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (11, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (12, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (13, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (14, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6), (15, <DictProxy object, typeid 'dict' at 0x2280c667220>, 6)]\n",
      "Running time 6-th round: 3761.508764743805 seconds\n",
      "Dataset size: 49064\n",
      "Epoch 1/50\n",
      "884/884 [==============================] - 11s 11ms/step - loss: 2.9291 - policy_loss: 1.9294 - value_loss: 0.9997 - val_loss: 2.9204 - val_policy_loss: 1.9209 - val_value_loss: 0.9995 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "884/884 [==============================] - 9s 10ms/step - loss: 2.9290 - policy_loss: 1.9293 - value_loss: 0.9997 - val_loss: 2.9221 - val_policy_loss: 1.9221 - val_value_loss: 1.0000 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "884/884 [==============================] - 9s 11ms/step - loss: 2.9292 - policy_loss: 1.9294 - value_loss: 0.9999 - val_loss: 2.9196 - val_policy_loss: 1.9204 - val_value_loss: 0.9992 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "884/884 [==============================] - 9s 11ms/step - loss: 2.9291 - policy_loss: 1.9294 - value_loss: 0.9997 - val_loss: 2.9219 - val_policy_loss: 1.9226 - val_value_loss: 0.9993 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "884/884 [==============================] - 9s 11ms/step - loss: 2.9289 - policy_loss: 1.9294 - value_loss: 0.9996 - val_loss: 2.9198 - val_policy_loss: 1.9204 - val_value_loss: 0.9994 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "884/884 [==============================] - 10s 11ms/step - loss: 2.9289 - policy_loss: 1.9294 - value_loss: 0.9995 - val_loss: 2.9209 - val_policy_loss: 1.9216 - val_value_loss: 0.9992 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "884/884 [==============================] - 9s 11ms/step - loss: 2.9289 - policy_loss: 1.9294 - value_loss: 0.9995 - val_loss: 2.9203 - val_policy_loss: 1.9205 - val_value_loss: 0.9997 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "884/884 [==============================] - 9s 10ms/step - loss: 2.9288 - policy_loss: 1.9294 - value_loss: 0.9994 - val_loss: 2.9199 - val_policy_loss: 1.9199 - val_value_loss: 1.0000 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "884/884 [==============================] - 9s 10ms/step - loss: 2.9292 - policy_loss: 1.9294 - value_loss: 0.9998 - val_loss: 2.9227 - val_policy_loss: 1.9208 - val_value_loss: 1.0019 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "884/884 [==============================] - 9s 10ms/step - loss: 2.9291 - policy_loss: 1.9294 - value_loss: 0.9997 - val_loss: 2.9201 - val_policy_loss: 1.9207 - val_value_loss: 0.9994 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "884/884 [==============================] - 9s 10ms/step - loss: 2.9290 - policy_loss: 1.9294 - value_loss: 0.9996 - val_loss: 2.9206 - val_policy_loss: 1.9215 - val_value_loss: 0.9992 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "884/884 [==============================] - 9s 11ms/step - loss: 2.9292 - policy_loss: 1.9294 - value_loss: 0.9998 - val_loss: 2.9205 - val_policy_loss: 1.9206 - val_value_loss: 0.9999 - lr: 0.0099\n",
      "Epoch 13/50\n",
      "884/884 [==============================] - 10s 11ms/step - loss: 2.9292 - policy_loss: 1.9294 - value_loss: 0.9998 - val_loss: 2.9219 - val_policy_loss: 1.9205 - val_value_loss: 1.0014 - lr: 0.0097\n",
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/tmp_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared_cache type: <class 'multiprocess.managers.DictProxy'>\n",
      "Number of args: 16\n",
      "[(0, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (1, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (2, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (3, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (4, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (5, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (6, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (7, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (8, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (9, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (10, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (11, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (12, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (13, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (14, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7), (15, <DictProxy object, typeid 'dict' at 0x2287a1fa490>, 7)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    self_play_dataset = flatten_dataset\n",
    "    \n",
    "    model = create_az_model()\n",
    "\n",
    "    for n in range(N_ROUNDS):\n",
    "\n",
    "        start_time = time.time()\n",
    "        ctx = mp.get_context(\"spawn\")\n",
    "\n",
    "        with SyncManager() as manager:\n",
    "\n",
    "            shared_cache = manager.dict()\n",
    "            print(f\"shared_cache type: {type(shared_cache)}\")\n",
    "            args = [(job_n, shared_cache, n+1) for job_n in range(n_cores)]\n",
    "            print(f\"Number of args: {len(args)}\")\n",
    "            print(args)\n",
    "\n",
    "            with ctx.Pool(n_cores) as pool:\n",
    "\n",
    "                round_dataset = pool.starmap(parallel_fn, args)\n",
    "\n",
    "        print(f\"Running time {n+1}-th round: {time.time() - start_time} seconds\")\n",
    "\n",
    "        flatten_round_dataset = []\n",
    "        for batch in round_dataset:\n",
    "            flatten_round_dataset += batch\n",
    "        self_play_dataset += flatten_round_dataset\n",
    "        print(f\"Dataset size: {len(self_play_dataset)}\")\n",
    "\n",
    "        trainer = Trainer(game = FourInARow, mcts = MCTS, model=model)\n",
    "        fit_history = trainer.train(self_play_dataset, n_epochs=50, batch_size=50, learning_rate=1e-2)\n",
    "\n",
    "        trainer.model.save(\"saved_model/tmp_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e\n",
    "\n",
    "https://stackoverflow.com/questions/16589791/most-efficient-property-to-hash-for-numpy-array\n",
    "\n",
    "https://developer.nvidia.com/tensorrt\n",
    "\n",
    "https://www.tensorflow.org/model_optimization\n",
    "\n",
    "https://www.tensorflow.org/model_optimization/guide/combine/collaborative_optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. averaging\n",
    "2. CPUTC add c=3 or 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
