{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f521e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf14ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33d9ed",
   "metadata": {},
   "source": [
    "# Game structure design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a121e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(ABC):\n",
    "    def next_play(recent_plays: np.array) -> int:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class AllC(Strategy):\n",
    "    def next_play(recent_plays: np.array = np.array([])) -> int:\n",
    "        return 1\n",
    "    \n",
    "class AllD(Strategy):\n",
    "    def next_play(recent_plays: np.array = np.array([])) -> int:\n",
    "        return -1\n",
    "        \n",
    "class RandomStrategy(Strategy):\n",
    "    def next_play(recent_plays: np.array = np.array([])) -> int:\n",
    "        return 1 if random.random()>=0.5 else -1\n",
    "    \n",
    "class TitForTatStrategy(Strategy):\n",
    "    def __init__(self, player):\n",
    "        if player==1:\n",
    "            self.player = 0\n",
    "            self.opponent = 1\n",
    "        elif player==2:\n",
    "            self.player = 1\n",
    "            self.opponent = 0\n",
    "        else:\n",
    "            return NotImplementedError\n",
    "        \n",
    "    def next_play(self, recent_plays: np.array = np.array([])) -> int:\n",
    "        if recent_plays[self.opponent,0] in [-1,1]:\n",
    "            return int(recent_plays[self.opponent,0])\n",
    "        else:\n",
    "            return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2514c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Axelrod:\n",
    "    \n",
    "    def __init__(self, memory: int = 10):\n",
    "        \n",
    "        self._memory_length = memory\n",
    "        self._games = np.zeros(shape=(2,self._memory_length))\n",
    "        self._score = np.array([0.0, 0.0])\n",
    "        self._game_duration = 0\n",
    "        \n",
    "    def play(self, strategy_1: Strategy, strategy_2: Strategy):\n",
    "        next_play_1 = strategy_1.next_play(self._games)\n",
    "        next_play_2 = strategy_2.next_play(self._games)\n",
    "        self._games = np.roll(self._games, 1, axis=1)\n",
    "        self._games[0,0] = next_play_1\n",
    "        self._games[1,0] = next_play_2\n",
    "        self._score += self.get_last_rewards()\n",
    "        self._game_duration += 1\n",
    "        #print(self._games, next_play_1, next_play_2, self.get_last_rewards(), self._score/self._game_duration)\n",
    "        \n",
    "    def get_last_rewards(self) -> np.array:\n",
    "        last_play = self._games[:,0]\n",
    "        if (last_play==np.array([1,1])).all():\n",
    "            return np.array([0.6,0.6])\n",
    "        elif (last_play==np.array([-1,-1])).all():\n",
    "            return np.array([0.2,0.2])\n",
    "        elif (last_play==np.array([-1,1])).all():\n",
    "            return np.array([1,0])\n",
    "        elif (last_play==np.array([1,-1])).all():\n",
    "            return np.array([0,1])\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported play combination\")\n",
    "    \n",
    "    def get_average_game_rewards(self) -> np.array:\n",
    "        return self._score/self._game_duration\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dba1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for i in range(5):\n",
    "    game.play(RandomStrategy, AllC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3845e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for i in range(5):\n",
    "    game.play(RandomStrategy, AllD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db72d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for i in range(5):\n",
    "    game.play(AllC, AllD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da080701",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for i in range(5):\n",
    "    game.play(RandomStrategy, RandomStrategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183d1951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.get_last_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "811e6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for i in range(9):\n",
    "    game.play(RandomStrategy, TitForTatStrategy(player=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0798f4e",
   "metadata": {},
   "source": [
    "# TF model design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8657a",
   "metadata": {},
   "source": [
    "https://arminnorouzi.github.io/posts/2023/05/blog-post-13/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9582cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_regularizer = tf.keras.regularizers.L2(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379e43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    \"\"\"\n",
    "    Generates a matrix of position encodings for an input sequence.\n",
    "\n",
    "    Args:\n",
    "      length: An integer representing the length of the input sequence.\n",
    "      depth: An integer representing the dimensionality of the encoding.\n",
    "\n",
    "    Returns:\n",
    "      A `tf.Tensor` of shape `(length, depth)` representing the position encoding matrix.\n",
    "    \"\"\"\n",
    "    depth = depth/2\n",
    "\n",
    "    positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "    depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "    angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1\n",
    "    )\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "pe = positional_encoding(length=MEMORY_LENGTH, depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9772253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs, kernel_regularizer=kernel_regularizer)\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        attention_output = self.mha(query=x, key=x, value=x)\n",
    "        x = self.add([x, attention_output])\n",
    "        x = self.layer_norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99693f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTower(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, n_layers=5, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.attention_layers = [SelfAttentionLayer(num_heads=8, key_dim=64) for _ in range(self.n_layers)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.attention_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95618d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "at = AttentionTower(num_heads=8, key_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53798bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QTower(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, n_layers = 5, n_neurons=10, output_size=2, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.ff = tf.keras.Sequential()\n",
    "        self.ff.add( tf.keras.layers.Flatten() )\n",
    "        for _ in range(self.n_layers):\n",
    "            self.ff.add( tf.keras.layers.Dense(n_neurons, activation=tf.nn.leaky_relu) )\n",
    "        self.ff.add( tf.keras.layers.Dropout(dropout_rate) )\n",
    "        self.ff.add( tf.keras.layers.Dense(output_size, activation=tf.keras.activations.sigmoid, kernel_regularizer=kernel_regularizer, name='policy') )\n",
    "    \n",
    "    def call(self, x):\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5907acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.cast(tf.one_hot(tf.cast(x + 1, tf.int32), 3), tf.float32)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b217138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 30, 3), dtype=float32, numpy=\n",
       "array([[[0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmbeddingLayer()(game._games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e3faaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AxelrodModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = EmbeddingLayer()\n",
    "        self.at = AttentionTower(num_heads=8, key_dim=64)\n",
    "        self.qt = QTower()\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        x = self.embed(x)\n",
    "        x = self.at(x)\n",
    "        q = self.qt(x)\n",
    "        \n",
    "        return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae5bda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AxelrodModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70bee027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\arrib\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.5589354 , 0.46187583]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(game._games[np.newaxis,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7bbcc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIStrategy(Strategy):\n",
    "    def __init__(self, model = AxelrodModel()):\n",
    "        self.model = model\n",
    "    def next_play(self, recent_plays: np.array) -> int:\n",
    "        x = self.model(recent_plays[np.newaxis,...])\n",
    "        return 2*np.argmax(x)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce7c4868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.],\n",
       "       [ 1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game._games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "560f9d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIStrategy().next_play(game._games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e79cff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AxelrodModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d01f750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.47946987, 0.48785147]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(game._games[np.newaxis,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68d433e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "ai = AIStrategy(model)\n",
    "for i in range(5):\n",
    "    game.play(ai, RandomStrategy)\n",
    "    ai.next_play(game._games)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6dc67",
   "metadata": {},
   "source": [
    "# Training with GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc4cbd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent_strategies = [RandomStrategy, AllC, AllD, TitForTatStrategy(player=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d713c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games_per_strategy = 10\n",
    "game_length = 50\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "gamma = 0.5\n",
    "\n",
    "ai = AIStrategy()\n",
    "\n",
    "for _ in range(n_games_per_strategy):\n",
    "    dataset = []\n",
    "    game = Axelrod(memory=MEMORY_LENGTH)\n",
    "    for strategy in opponent_strategies:\n",
    "        for _ in range(game_length):\n",
    "            current_state = game._games\n",
    "            game.play(ai, strategy)\n",
    "            dataset.append( (current_state, game.get_last_rewards()[0], tf.math.reduce_max(ai.model(game._games[np.newaxis,...])) ) )\n",
    "\n",
    "    states, rewards, max_q_primes = list(zip(*dataset))\n",
    "    states = tf.concat([b[np.newaxis, :] for b in states], axis=0)\n",
    "    rewards = tf.cast(tf.stack(rewards), dtype=tf.float32)\n",
    "    max_q_primes = tf.stack(max_q_primes)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        q_0s = ai.model(states)\n",
    "        actions = tf.argmax(q_0s, axis=1)\n",
    "        action_selector = tf.cast(tf.stack([1-actions,actions], axis=1), dtype=tf.float32)\n",
    "        loss = q_0s + tf.transpose((rewards+gamma*max_q_primes)[np.newaxis,...]) * action_selector\n",
    "\n",
    "    grad = tape.gradient(loss, ai.model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grad, ai.model.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da0d58e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52, 0.34])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for _ in range(50):\n",
    "    game.play(ai, RandomStrategy)\n",
    "    #print(_, game._games, game.get_last_rewards())\n",
    "game.get_average_game_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ec907b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for _ in range(50):\n",
    "    game.play(ai, AllD)\n",
    "    #print(_, game._games, game.get_last_rewards())\n",
    "game.get_average_game_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1dd7de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.848, 0.228])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for _ in range(50):\n",
    "    game.play(ai, AllC)\n",
    "    #print(_, game._games, game.get_last_rewards())\n",
    "game.get_average_game_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a640bb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.412, 0.392])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for _ in range(50):\n",
    "    game.play(ai, TitForTatStrategy(player=2))\n",
    "    #print(_, game._games, game.get_last_rewards())\n",
    "game.get_average_game_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ff1e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [1 0]\n",
      "1 [[-1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "2 [[-1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "3 [[-1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "4 [[-1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "5 [[-1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "6 [[-1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "7 [[-1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "8 [[-1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "9 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "10 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "11 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "12 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "13 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "14 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "15 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "16 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "17 [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.2 0.2]\n",
      "18 [[ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "19 [[ 1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.6 0.6]\n",
      "20 [[ 1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.6 0.6]\n",
      "21 [[ 1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]] [0.6 0.6]\n",
      "22 [[ 1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.  0.]] [0.6 0.6]\n",
      "23 [[-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.  0.]] [1 0]\n",
      "24 [[ 1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.]\n",
      " [-1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.  0.]] [0 1]\n",
      "25 [[ 1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.]\n",
      " [ 1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.  0.]] [0.6 0.6]\n",
      "26 [[ 1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.]\n",
      " [ 1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.  0.]] [0.6 0.6]\n",
      "27 [[ 1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.]\n",
      " [ 1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.  0.]] [0.6 0.6]\n",
      "28 [[ 1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.]\n",
      " [ 1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  0.]] [0.6 0.6]\n",
      "29 [[ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.]] [0.6 0.6]\n",
      "30 [[ 1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "31 [[ 1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "33 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "34 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "35 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "36 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "37 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
      "   1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "38 [[-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "   1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [1 0]\n",
      "39 [[-1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [-1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.\n",
      "   1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.2 0.2]\n",
      "40 [[-1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [-1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "   1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0.2 0.2]\n",
      "41 [[-1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "   1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1.]] [0.2 0.2]\n",
      "42 [[ 1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.]\n",
      " [-1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "43 [[ 1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.]\n",
      " [ 1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "44 [[ 1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.]\n",
      " [ 1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.]] [0.6 0.6]\n",
      "45 [[ 1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.]\n",
      " [ 1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.]] [0.6 0.6]\n",
      "46 [[-1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.]\n",
      " [ 1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.]] [1 0]\n",
      "47 [[-1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.]] [0.2 0.2]\n",
      "48 [[-1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.]\n",
      " [-1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.]] [0.2 0.2]\n",
      "49 [[-1. -1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.]\n",
      " [-1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.]] [0.2 0.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.412, 0.392])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for _ in range(50):\n",
    "    game.play(ai, TitForTatStrategy(player=2))\n",
    "    print(_, game._games, game.get_last_rewards())\n",
    "game.get_average_game_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbba115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca1a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e304fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7343df8",
   "metadata": {},
   "source": [
    "# Build training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e34972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_0_to_minus_1(input_tensor: tf.Tensor):\n",
    "\n",
    "    condition = tf.equal(input_tensor, 0)\n",
    "\n",
    "    modified_tensor = tf.where(condition, tf.constant(-1, dtype=tf.int64), input_tensor)\n",
    "    return modified_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "17e68ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent_strategies = [RandomStrategy, AllC, AllD, TitForTatStrategy(player=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "1138f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games_per_strategy = 10\n",
    "game_length = 30\n",
    "\n",
    "ai = AIStrategy()\n",
    "\n",
    "dataset = []\n",
    "for _ in range(n_games_per_strategy):\n",
    "    game = Axelrod(memory=MEMORY_LENGTH)\n",
    "    for strategy in opponent_strategies:\n",
    "        for _ in range(game_length):\n",
    "            current_state = game._games\n",
    "            game.play(ai, strategy)\n",
    "            dataset.append( (current_state, ai.model(current_state[np.newaxis,...]), game.get_last_rewards()[0], tf.math.reduce_max(ai.model(game._games[np.newaxis,...])) ) )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "7667b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "4e415e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "states, q_0s, rewards, max_q_primes = list(zip(*dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "f28977b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = tf.concat([b[np.newaxis, :] for b in states], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "b95e6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_0s = tf.concat( q_0s, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "9f70c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = tf.cast(tf.stack(rewards), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "461e12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_q_primes = tf.stack(max_q_primes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "fb31decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = tf.convert_to_tensor([0.05,-0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "24a560ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = tf.repeat( alpha0[np.newaxis,:], len(dataset), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "7d57d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = tf.transpose( tf.cast(map_0_to_minus_1( tf.argmax(q_0s, axis=1)[np.newaxis,...] ), dtype=tf.float32) )*alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "b50e74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_q = (1-alpha)*q_0s + alpha*tf.transpose( (rewards+gamma*max_q_primes)[tf.newaxis,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "9c9b9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return max(lr * tf.math.exp(-0.01 * (epoch - 10)), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "9ab1d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.model.compile(\n",
    "    # Optimizer\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    # Loss function to minimize\n",
    "    loss=[tf.keras.losses.MeanSquaredError()],\n",
    "    # List of metrics to monitor\n",
    "    # metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    "    run_eagerly=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "41b81426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 6s 148ms/step - loss: 0.1263 - val_loss: 0.1325 - lr: 0.1000\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.1013 - val_loss: 0.0711 - lr: 0.1000\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.0693 - val_loss: 0.0630 - lr: 0.1000\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.0498 - val_loss: 0.0327 - lr: 0.1000\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.0242 - val_loss: 0.0169 - lr: 0.1000\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.0137 - val_loss: 0.0109 - lr: 0.1000\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.0093 - val_loss: 0.0084 - lr: 0.1000\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.0072 - val_loss: 0.0060 - lr: 0.1000\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.0052 - val_loss: 0.0047 - lr: 0.1000\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.5031 - val_loss: 0.8528 - lr: 0.1000\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.7684 - val_loss: 0.6703 - lr: 0.1000\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.6038 - val_loss: 0.5362 - lr: 0.0990\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 3s 132ms/step - loss: 0.4997 - val_loss: 0.4590 - lr: 0.0970\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.4373 - val_loss: 0.4101 - lr: 0.0942\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.3962 - val_loss: 0.3766 - lr: 0.0905\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.3676 - val_loss: 0.3525 - lr: 0.0861\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.3465 - val_loss: 0.3346 - lr: 0.0811\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 3s 130ms/step - loss: 0.3308 - val_loss: 0.3211 - lr: 0.0756\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 3s 131ms/step - loss: 0.3189 - val_loss: 0.3106 - lr: 0.0698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1ef340e1850>"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.model.fit(\n",
    "    x=states,\n",
    "    y=new_q,\n",
    "    epochs=100,\n",
    "    batch_size=50,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "    ],\n",
    "    validation_split=0.1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "e5c78b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "1 [[ 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "2 [[ 1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "3 [[ 1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "4 [[ 1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "5 [[ 1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "6 [[ 1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "7 [[ 1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "8 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "9 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "10 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "11 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "12 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "13 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "14 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "15 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "16 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "17 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "18 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "19 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "20 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "21 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "22 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "23 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.  0.]] [0 1]\n",
      "24 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.  0.]] [0 1]\n",
      "25 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.  0.]] [0 1]\n",
      "26 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.  0.]] [0 1]\n",
      "27 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.]] [0 1]\n",
      "28 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.]] [0 1]\n",
      "29 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "30 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "31 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "32 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "34 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "35 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "36 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "37 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "38 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "39 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "40 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "41 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "42 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "43 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "44 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "45 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "46 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "47 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "48 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n",
      "49 [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]] [0 1]\n"
     ]
    }
   ],
   "source": [
    "game = Axelrod(memory=MEMORY_LENGTH)\n",
    "for _ in range(50):\n",
    "    game.play(ai, AllD)\n",
    "    print(_, game._games, game.get_last_rewards())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "57dae880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.44734684, 0.4533372 ]], dtype=float32)>"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.model(game._games[np.newaxis,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f991d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
